{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ev7mKEvgbYcZ"
   },
   "source": [
    "# Lab 10: Fully Connected Neural Networks\n",
    "\n",
    "In this assignment, we will learn fully connected neural network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwZwfFQYbYcc"
   },
   "source": [
    "## 1. Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHnoQz3MbYcd"
   },
   "source": [
    "This assignement should be run on Google Colab where you can use free GPU to accelerate the computation. Please refer to our slides to set up GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab][colab badge]][colab]\n",
    "\n",
    "[colab badge]: https://colab.research.google.com/assets/colab-badge.svg\n",
    "[colab]: https://colab.research.google.com/github/lduran2/CIS3715_DataScience_2022/blob/lab10/Lab10/Lab10.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4Rte_TebYce"
   },
   "source": [
    "### 1. Install Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6583,
     "status": "ok",
     "timestamp": 1649559863527,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "outputId": "3ff45b08-cc1c-4281-b8a8-f31d06275642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision   # install pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqu1YdX2bYch"
   },
   "source": [
    "### 2. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1649559865200,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "outputId": "6987f9ee-b3ff-43c5-d4ea-4cd7d2a1ee5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 10 03:04:26 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!/opt/bin/nvidia-smi  #show GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqmII1sAbYcj"
   },
   "source": [
    "### 3. Mount to google drive (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17744,
     "status": "ok",
     "timestamp": 1649274810388,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "id": "HdWuV25Qb-TM",
    "outputId": "09e93d6a-5e99-4510-e3be-eca9853e6566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bAPbFl0bYck"
   },
   "source": [
    "### 4. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nVVA8yeXv9c"
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTnQJNfyhmaE"
   },
   "outputs": [],
   "source": [
    "args={}\n",
    "args['batch_size']=100\n",
    "args['test_batch_size']=100\n",
    "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n",
    "args['lr']=0.01 #Learning rate is how fast it will decend. \n",
    "args['log_interval']=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_rnd(a_seed):\n",
    "    '''\n",
    "    Seeds all relevant RND libaries.\n",
    "    '''\n",
    "    # import and seed numpy if unused\n",
    "    import numpy\n",
    "    numpy.random.seed(a_seed)\n",
    "    # seed Pytorch\n",
    "    torch.manual_seed(a_seed)\n",
    "    # seed the GPU(s)\n",
    "    torch.cuda.manual_seed_all(a_seed)\n",
    "# end seed_rnd(a_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a constant random seed to make experiment repeatable\n",
    "seed_rnd(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be added to GPU when it will be trained/tested with each other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1649276322480,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "outputId": "7d252d46-624d-4416-9851-8cdff1ce97da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# build an mlp\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 256)   # linear layer (784 -> 256)\n",
    "        self.fc2 = nn.Linear(256,128)  # linear layer (256 -> 128)\n",
    "        self.fc3 = nn.Linear(128,10)  # linear layer (128 -> 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = x.view(-1,28*28) #input layer\n",
    "        h1 = F.relu(self.fc1(h0)) # hidden layer 1\n",
    "        h2 = F.relu(self.fc2(h1)) # hidden layer 2\n",
    "        h3 = self.fc3(h2) # output layer\n",
    "\n",
    "        return h3\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer was moved down to the train/test loop\n",
    "because it needs to be updated for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0U9yHGoTZi3e"
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvuVjPqPabRC"
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OipUVawbYcr"
   },
   "source": [
    "## 2. Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have changed the `train` and `test` functions\n",
    "and added some of my own to make it possible to aggregate loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `train` and its callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTrainReport(epoch, i_xamp, N_XAMPS, pc_accuracy, r_loss):\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, i_xamp, N_XAMPS, pc_accuracy, r_loss))\n",
    "# end def printTrainReport(epoch, i_xamp, N_XAMPS, pc_accuracy, r_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAppendLossTo(queue):\n",
    "    def appendLossToQueue(epoch, i_xamp, N_XAMPS, pc_accuracy, r_loss):\n",
    "        queue.append(r_loss)\n",
    "    # end def appendLossToQueue(epoch, i_xamp, N_XAMPS, pc_accuracy, r_loss)\n",
    "    return appendLossToQueue\n",
    "# end def createAppendLossTo(queue)(epoch, i_xamp, N_XAMPS, pc_accuracy, r_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YopP0oK5ca2u"
   },
   "outputs": [],
   "source": [
    "def train(epoch, callbacks=[printTrainReport]):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #to do a one-step update on our parameter.\n",
    "        optimizer.step()\n",
    "\n",
    "        #Apply callbacks to the loss periodically. \n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            for callback in callbacks:\n",
    "                callback(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `test` and its callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTestReport(epoch, r_test_loss, N_CORRECTS, N_XAMPS, pc_accuracy):\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "        .format(r_test_loss, N_CORRECTS, N_XAMPS, pc_accuracy))\n",
    "# end def printTestReport(epoch, r_test_loss, N_CORRECTS, N_XAMPS, pc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAppendAccuracyTo(queue):\n",
    "    def appendAccuracyToQueue(\n",
    "          epoch, r_test_loss, N_CORRECTS, N_XAMPS, pc_accuracy):\n",
    "        queue.append(pc_accuracy)\n",
    "    # end def appendAccuracyToQueue(\n",
    "    #     epoch, r_test_loss, N_CORRECTS, N_XAMPS, pc_accuracy)\n",
    "    return appendAccuracyToQueue\n",
    "# end def createAppendAccuracyTo(queue)(\n",
    "#     epoch, r_test_loss, N_CORRECTS, N_XAMPS, pc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLn-uP_sct-a"
   },
   "outputs": [],
   "source": [
    "def test(epoch=-1, callbacks=[printTestReport]):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    for callback in callbacks:\n",
    "        callback(\n",
    "            epoch, test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GA50s29XbYcs"
   },
   "source": [
    "### 1. Please use other activation functions, e.g., sigmoid, tanh, and then plot the training loss and testing accuracy. \n",
    "\n",
    "When plotting the training loss, the x-axis is iteration and the y-axis is training loss. When plotting the testing accuracy,  the x-axis is epoch and the y-axis is the training loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  0.,  1.],\n",
      "        [-2.,  0.,  2.],\n",
      "        [ 1.,  0.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "#a test value for testing activation functions\n",
    "test_s = torch.Tensor([[-1, 0, 1], [-2, 0, 2], [1, 0, 1]])\n",
    "print(test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2689, 0.5000, 0.7311],\n",
      "        [0.1192, 0.5000, 0.8808],\n",
      "        [0.7311, 0.5000, 0.7311]])\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(s):\n",
    "    return 1/(1 + torch.exp(-s))\n",
    "# end def sigmoid(s)\n",
    "\n",
    "print(sigmoid(test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7616,  0.0000,  0.7616],\n",
      "        [-0.9640,  0.0000,  0.9640],\n",
      "        [ 0.7616,  0.0000,  0.7616]])\n"
     ]
    }
   ],
   "source": [
    "def tanh(s):\n",
    "    '''\n",
    "    Hyperbolic tangent.\n",
    "    '''\n",
    "    return (2*sigmoid(2*s) - 1)\n",
    "# end def tanh(s)\n",
    "\n",
    "print(tanh(test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0100,  0.0000,  1.0000],\n",
      "        [-0.0200,  0.0000,  2.0000],\n",
      "        [ 1.0000,  0.0000,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "def create_leaky_relu(alpha=1e-2):\n",
    "    '''\n",
    "    ReLU that leaks on negative input.\n",
    "    @param alpha : float = negative slope\n",
    "    '''\n",
    "    def leaky_relu(s):\n",
    "        return torch.max(alpha*s, s)\n",
    "    # end def leaky_relu(s)\n",
    "    return leaky_relu\n",
    "# end def create_leaky_relu(alpha=1e-2)(s)\n",
    "\n",
    "# get a default leaky ReLU\n",
    "leaky_relu = create_leaky_relu()\n",
    "\n",
    "print(leaky_relu(test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -0., 1.],\n",
      "        [0., -0., 2.],\n",
      "        [1., -0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# the original Re(ctified) L(inear) U(nit)\n",
    "# relu = -0. if s = 0\n",
    "relu = create_leaky_relu(alpha=-0.)\n",
    "\n",
    "print(relu(test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6321,  0.0000,  1.0000],\n",
      "        [-0.8647,  0.0000,  2.0000],\n",
      "        [ 1.0000,  0.0000,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "def create_elu(alpha=1.):\n",
    "    '''\n",
    "    E(xponential)=L(inear) U(nit).\n",
    "    @param alpha : float = negative coefficient\n",
    "    '''\n",
    "    def elu(s):\n",
    "        return (s + (-s + alpha*(torch.exp(s) - 1))*(s <= 0))\n",
    "    # end def elu(s)\n",
    "    return elu\n",
    "# end def create_elu(alpha=1.)(s)\n",
    "\n",
    "# get a default ELU\n",
    "elu = create_elu()\n",
    "\n",
    "print(elu(test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Pandas data frame===\n",
      "   a   b\n",
      "0  1   9\n",
      "1  4  16\n",
      "===Pytorch tensor===\n",
      "tensor([[ 1.,  4.],\n",
      "        [ 9., 16.]])\n"
     ]
    }
   ],
   "source": [
    "def testTensorOrientation():\n",
    "    #show the Pandas data frame\n",
    "    import pandas as pd\n",
    "    print('===Pandas data frame===')\n",
    "    print(pd.DataFrame({'a': [1, 2], 'b': [3, 4]})**2)\n",
    "    # show the Pytorch tensor\n",
    "    print('===Pytorch tensor===')\n",
    "    print(torch.Tensor([[1, 2], [3, 4]])**2)\n",
    "# end def testTensors()\n",
    "\n",
    "testTensorOrientation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous cell,\n",
    "we see that `pandas` data frames are oriented by column\n",
    "whereas Pytorch tensors are oriented by row instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0900, 0.2447, 0.6652],\n",
      "        [0.0159, 0.1173, 0.8668],\n",
      "        [0.4223, 0.1554, 0.4223]])\n"
     ]
    }
   ],
   "source": [
    "def softmax(s):\n",
    "    '''\n",
    "    For each column, each cell is\n",
    "        exp(s)/sum(exp(s)).\n",
    "    '''\n",
    "    # sum along axis=1, which is by rows\n",
    "    norm = torch.sum(torch.exp(s), 1)\n",
    "    # we reshape to a column vector of norms\n",
    "    norm_cols = norm.reshape(-1,1)\n",
    "    return torch.exp(s)/norm_cols\n",
    "# end def softmax(s)\n",
    "\n",
    "print(softmax(test_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the activation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of models\n",
    "models = [model]\n",
    "# model names\n",
    "model_names = ['Net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation functions\n",
    "activates = (sigmoid, tanh, relu, leaky_relu, elu, softmax)\n",
    "model_names += ('Sigmoid', 'tanh', 'ReLU', 'Leaky ReLU', 'ELU', 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an mlp that uses a specific activation function\n",
    "class Activation(nn.Module):\n",
    "    def __init__(self, activate):\n",
    "        super(Activation, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 256)   # linear layer (784 -> 256)\n",
    "        self.fc2 = nn.Linear(256,128)  # linear layer (256 -> 128)\n",
    "        self.fc3 = nn.Linear(128,10)  # linear layer (128 -> 10)\n",
    "\n",
    "        self.activate = activate\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = x.view(-1,28*28) #input layer\n",
    "        h1 = self.activate(self.fc1(h0)) # hidden layer 1\n",
    "        h2 = self.activate(self.fc2(h1)) # hidden layer 2\n",
    "        h3 = self.activate(self.fc3(h2)) # output layer\n",
    "\n",
    "        return h3\n",
    "# end class Activation(nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#create the activation function models\n",
    "for activate in activates:\n",
    "    models.append(Activation(activate))\n",
    "\n",
    "#print the last (activation) model\n",
    "# all activation models will look identical as strings\n",
    "print(models[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158181,
     "status": "ok",
     "timestamp": 1649276492527,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "outputId": "aaa6553d-5c92-4714-db39-37f12e88f997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Net======\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306634\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.283218\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.243291\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.219450\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.197454\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.162927\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.101262\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.088319\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.044811\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 1.943084\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.878040\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 1.835300\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.738544\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 1.663665\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.524293\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 1.604650\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.409848\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 1.304045\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.246239\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 1.137151\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.151942\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 1.043166\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.956376\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.956012\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.870184\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.862103\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.840777\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.695064\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.761660\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.691901\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.586627\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.744565\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.643152\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.623596\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.616978\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.621039\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.610111\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.473731\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.557010\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.579489\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.613075\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.591935\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.372832\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.583918\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.409139\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.675892\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.451818\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.542194\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.553645\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.442634\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.339348\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.368448\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.572999\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.469368\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.257759\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.335056\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.538505\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.391627\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.562195\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.410992\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 8876/10000 (89%)\n",
      "\n",
      "======Net======\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.399774\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.379663\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.627829\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.397357\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.383630\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.452376\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.489288\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.473017\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.415708\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.464188\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.366594\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.430506\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.318941\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.543335\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.367856\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.494426\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.409596\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.457799\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.391606\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.414712\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.330018\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.272714\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.296639\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.429885\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.221101\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.333206\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.355795\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.255603\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.391635\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.483133\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.422155\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.286567\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.338461\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.434588\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.405150\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.312879\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.594624\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.214505\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.224156\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.406338\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.379648\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.321756\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.337265\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.422404\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.201302\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.400050\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.419835\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.290248\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.458490\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.255630\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.268195\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.324267\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.356298\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.259585\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.314497\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.384086\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.370070\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.338435\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.202090\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.219958\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 9096/10000 (91%)\n",
      "\n",
      "======Net======\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.310612\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.344581\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.288972\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.254061\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.278124\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.310810\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.278179\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.274001\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.409172\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.157468\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.186067\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.196725\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.380880\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.269760\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.243439\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.475405\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.354018\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.303918\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.389703\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.401825\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.399777\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.319753\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.368018\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.228401\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.367345\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.250831\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.271977\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.256989\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.359790\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.378196\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.372908\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.297559\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.299527\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.439384\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.328038\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.435900\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.285770\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.218490\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.349377\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.356038\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.251137\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.167943\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.252555\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.266104\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.276757\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.308947\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.292853\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.306861\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.256060\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.220391\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.293950\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.204429\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.209162\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.163139\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.214819\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.236999\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.168531\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.153035\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.246030\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.259527\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 9242/10000 (92%)\n",
      "\n",
      "======Net======\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.173839\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.150599\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.211397\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.192565\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.353607\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.387675\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.255716\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.381510\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.243230\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.218576\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.318384\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.192815\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.234065\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.226019\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.133062\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.298073\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.296669\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.297179\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.253937\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.330013\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.237868\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.270620\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.277291\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.220139\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.262396\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.389962\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.289756\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.201775\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.341208\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.256788\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.155356\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.261566\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.317590\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.228085\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.245143\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.277323\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.193843\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.171387\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.289905\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.131425\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.469161\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.253517\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.348610\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.313538\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.171861\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.194615\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.381640\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.246391\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.238892\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.225695\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.251557\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.283490\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.263955\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.143742\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.175063\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.198700\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.293221\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.208227\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.183419\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.385492\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 9292/10000 (93%)\n",
      "\n",
      "======Net======\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.196101\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.214427\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.220928\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.231232\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.320792\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.341965\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.269447\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.146138\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.239773\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.301313\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.313607\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.200033\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.331783\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.171923\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.283958\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.169561\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.145149\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.269138\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.328254\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.232411\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.288711\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.205994\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.170326\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.321970\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.205537\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.268727\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.254855\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.187433\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.152845\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.323617\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.184609\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.286067\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.238668\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.235213\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.160114\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.223740\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.263706\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.127062\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.320165\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.200502\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.254863\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.228058\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.150491\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.298419\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.265115\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.313478\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.400687\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.254307\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.411232\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.252199\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.192884\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.197047\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.198684\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.231125\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.175323\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.200652\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.389230\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.270632\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.182450\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.272872\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 9363/10000 (94%)\n",
      "\n",
      "======Net======\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.326880\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 0.171844\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.297064\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 0.224063\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.325835\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.201521\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.208427\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 0.157656\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.344112\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 0.230219\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.283634\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 0.188548\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.098515\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 0.166354\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.368890\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.236484\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.283290\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 0.245295\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.138387\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 0.155236\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.223095\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 0.109360\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.276156\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 0.159575\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.420633\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.243916\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.222244\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 0.150892\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.155619\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 0.158640\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.232056\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 0.174476\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.227046\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 0.212674\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.212036\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.187224\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.371251\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 0.250171\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.206238\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 0.123448\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.241522\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 0.252150\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.180600\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 0.192298\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.119325\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.241984\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.208063\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 0.171532\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.241359\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 0.207601\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.262681\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 0.295932\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.084202\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 0.222842\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.194052\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.155681\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.132170\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 0.222951\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.166416\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 0.206566\n",
      "\n",
      "Test set: Average loss: 0.0020, Accuracy: 9411/10000 (94%)\n",
      "\n",
      "======Net======\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.121304\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 0.183966\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.088946\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 0.121630\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.181356\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.188119\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.130232\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 0.322329\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.205162\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 0.196463\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.340132\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 0.221374\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.247730\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 0.150573\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.153589\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.164342\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.358457\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 0.148129\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.228548\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 0.254477\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.133012\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 0.212458\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.160244\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 0.212532\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.216549\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.113563\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.118540\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 0.232880\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.094602\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 0.183410\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.207755\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 0.158581\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.284698\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 0.092336\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.190531\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.178734\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.271007\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 0.150168\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.153816\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 0.174241\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.136427\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 0.291132\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.136559\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 0.189865\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.173774\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.232579\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.168875\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 0.118091\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.239984\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 0.153645\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.198682\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 0.225176\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.095134\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 0.157878\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.189953\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.159223\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.214408\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 0.314386\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.235813\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 0.153920\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 9445/10000 (94%)\n",
      "\n",
      "======Net======\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.282852\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 0.208869\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.088616\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 0.099759\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.193757\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.396963\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.166350\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 0.271413\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.108450\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 0.143514\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.162410\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 0.149454\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.287392\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 0.094512\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.124962\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.232341\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.172359\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 0.206966\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.157389\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 0.326064\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.138518\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 0.143000\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.117807\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 0.172103\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.102215\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.175884\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.134565\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 0.149606\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.119546\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 0.078577\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.170561\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 0.167171\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.168368\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 0.111611\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.093618\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.202810\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.203764\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 0.162192\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.144815\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 0.139765\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.107766\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 0.186939\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.211997\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 0.239993\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.164266\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.106380\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.185694\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 0.172412\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.200009\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 0.082085\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.204102\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 0.100065\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.183687\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 0.082286\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.172565\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.128616\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.197994\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 0.218569\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.107888\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 0.262551\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 9486/10000 (95%)\n",
      "\n",
      "======Net======\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.116864\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 0.241381\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.200043\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 0.111564\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.195012\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.118138\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.203121\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 0.194007\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.187061\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 0.186482\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.176803\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 0.092262\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.119376\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 0.186602\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.090386\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.221889\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.166514\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 0.145427\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.234629\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 0.137930\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.290636\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 0.108035\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.100669\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 0.106605\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.130883\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.142037\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.168767\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 0.203629\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.118280\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 0.071901\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.187095\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 0.159567\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.112449\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 0.152179\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.157374\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.308718\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.157059\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 0.058725\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.212255\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 0.086326\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.149812\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 0.175373\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.129978\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 0.243326\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.294107\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.061962\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.210943\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 0.156316\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.112376\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 0.189037\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.183613\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 0.116088\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.159933\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 0.095570\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.127169\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.138259\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.239215\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 0.231312\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.090699\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 0.153682\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 9516/10000 (95%)\n",
      "\n",
      "======Net======\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.202067\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 0.145540\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 0.148687\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 0.129069\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 0.140268\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 0.178158\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 0.126814\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 0.111004\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.067100\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 0.089722\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.243273\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 0.112377\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.217036\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 0.155584\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 0.195530\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.172698\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.196001\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 0.082852\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 0.108323\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 0.181141\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.128984\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 0.075958\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 0.081379\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 0.127250\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.194535\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.166428\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 0.123078\n",
      "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 0.138637\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 0.111103\n",
      "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 0.198985\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.115433\n",
      "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 0.121282\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.163918\n",
      "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 0.107167\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 0.196590\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 0.222383\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.086638\n",
      "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 0.141484\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 0.143064\n",
      "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 0.124022\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.140801\n",
      "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 0.295021\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 0.118694\n",
      "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 0.182762\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 0.201255\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 0.118849\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 0.173755\n",
      "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 0.127656\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.141746\n",
      "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 0.187318\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.163967\n",
      "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 0.093308\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 0.212036\n",
      "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 0.106485\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 0.111988\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 0.165897\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.134316\n",
      "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 0.086818\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 0.227980\n",
      "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 0.122983\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 9549/10000 (95%)\n",
      "\n",
      "\n",
      "======Sigmoid======\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.311714\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.302858\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.311781\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.305431\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.311798\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.300590\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.300497\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.312740\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.303679\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.310039\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.305231\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 2.303115\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.305760\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 2.299932\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.304341\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.314375\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.307608\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 2.305253\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.300943\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 2.303362\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.297019\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 2.297056\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 2.296881\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 2.301716\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.313420\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.299446\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 2.299428\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 2.294474\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 2.301371\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 2.306116\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.311999\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 2.295733\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.311124\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 2.304282\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 2.307973\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.303718\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 2.304054\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 2.302814\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 2.300350\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 2.300225\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.299036\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 2.304636\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 2.291973\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 2.299454\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 2.304886\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.313521\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 2.309282\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 2.306940\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.310597\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 2.300305\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.305738\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 2.306954\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 2.304390\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 2.298170\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 2.300722\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.301283\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 2.313143\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 2.301466\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 2.306578\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 2.301820\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 980/10000 (10%)\n",
      "\n",
      "======Sigmoid======\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.299139\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 2.309656\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 2.312199\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 2.303694\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 2.306472\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 2.300001\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 2.293368\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 2.313665\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 2.295205\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 2.304406\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.304771\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 2.309631\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 2.296563\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 2.307643\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 2.305622\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 2.300215\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.299741\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 2.314943\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 2.314784\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 2.305987\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.305500\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 2.299958\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 2.299291\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 2.296329\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 2.297525\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 2.306121\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 2.307178\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 2.308848\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 2.298038\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 2.308347\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.295594\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 2.314904\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.312028\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 2.312299\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 2.299721\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 2.302787\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 2.311110\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 2.305215\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 2.299597\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 2.319872\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.294405\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 2.301454\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 2.308989\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 2.308161\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 2.299496\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 2.308040\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 2.303804\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 2.298790\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 2.309390\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 2.312517\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 2.297560\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 2.315066\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 2.313570\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 2.304584\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 2.309136\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 2.311704\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 2.302762\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 2.300692\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 2.313016\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 2.309827\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 980/10000 (10%)\n",
      "\n",
      "======Sigmoid======\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.301426\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 2.299826\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 2.308227\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 2.306637\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 2.313298\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 2.307658\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 2.306774\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 2.310077\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 2.295360\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 2.308987\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 2.305265\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 2.311660\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 2.313496\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 2.302577\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 2.298947\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 2.310692\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 2.302651\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 2.303964\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 2.310879\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 2.311272\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 2.308067\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 2.304316\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 2.301700\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 2.305791\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 2.297095\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 2.303167\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 2.307110\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 2.290977\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 2.307916\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 2.299517\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 2.313706\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 2.315749\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.298195\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 2.301999\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 2.305729\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 2.305623\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 2.306691\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 2.296702\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 2.311540\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 2.296776\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 2.302448\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 2.307863\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 2.304890\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 2.305032\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 2.312225\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 2.299098\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 2.307199\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 2.296027\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 2.305443\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 2.309034\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 2.311742\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 2.301019\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 2.307572\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 2.302099\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 2.304250\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 2.309350\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 2.304334\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 2.301538\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 2.311164\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 2.300142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 980/10000 (10%)\n",
      "\n",
      "======Sigmoid======\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.302617\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 2.302242\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 2.291299\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 2.300311\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 2.309285\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 2.319822\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 2.303766\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 2.300344\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 2.300280\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 2.295486\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 2.298883\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 2.301844\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 2.302170\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 2.299992\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 2.310342\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 2.300421\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 2.306796\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 2.299403\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 2.306055\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 2.311745\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 2.296739\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 2.308270\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 2.292434\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 2.301657\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 2.301601\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 2.299414\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 2.303653\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 2.311088\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 2.310880\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 2.311685\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 2.301689\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 2.316525\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.306461\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 2.306209\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 2.309471\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 2.304615\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 2.312331\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 2.298404\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 2.304608\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 2.310954\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 2.312852\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 2.304426\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 2.315548\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 2.308911\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 2.305229\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 2.302356\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 2.308746\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 2.297218\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 2.304900\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 2.298692\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 2.300449\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 2.303782\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 2.304145\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 2.303726\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 2.312837\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 2.304864\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 2.299262\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 2.300517\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 2.319576\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 2.307265\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 980/10000 (10%)\n",
      "\n",
      "======Sigmoid======\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.305756\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 2.312575\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 2.309329\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 2.304173\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 2.304966\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 2.309532\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 2.295777\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 2.297522\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 2.313351\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 2.298360\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 2.302473\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 2.295347\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 2.307622\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 2.315577\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 2.316386\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 2.316983\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 2.315690\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 2.308827\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 2.309229\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 2.302911\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 2.304789\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 2.318896\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 2.307837\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 2.300155\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 2.296562\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 2.304032\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 2.308122\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 2.295814\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 2.307728\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 2.310315\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 2.319418\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 2.298318\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.305470\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 2.310364\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 2.291988\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 2.297386\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 2.307028\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 2.312197\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 2.314114\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 2.298722\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 2.305371\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 2.304045\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 2.301567\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 2.298988\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 2.307386\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 2.306176\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 2.302321\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 2.303528\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 2.303532\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 2.310534\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 2.301936\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 2.306203\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 2.290212\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 2.307352\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 2.302606\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 2.305286\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 2.317240\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 2.307232\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 2.314268\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 2.314505\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 980/10000 (10%)\n",
      "\n",
      "======Sigmoid======\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.305275\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 2.299480\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 2.308102\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 2.304750\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 2.297886\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 2.302549\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 2.305429\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 2.305327\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 2.309975\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 2.305750\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 2.306227\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 2.298142\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 2.306715\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 2.302763\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 2.297498\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 2.295056\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 2.308180\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 2.306699\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 2.298769\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 2.303039\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 2.305321\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 2.307308\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 2.311121\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 2.301001\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 2.298322\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 2.308596\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 2.307229\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 2.310601\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 2.303569\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 2.306001\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 2.312068\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 2.305820\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.306306\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 2.305789\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 2.313631\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 2.291427\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 2.294452\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 2.307804\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 2.302293\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 2.310582\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 2.296521\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 2.300376\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 2.305125\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 2.298286\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 2.315583\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 2.304213\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 2.299327\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 2.315890\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 2.310234\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 2.318239\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 2.301581\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 2.305323\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 2.308580\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 2.304132\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 2.306069\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 2.309712\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 2.305475\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 2.311649\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 2.306368\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 2.306690\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 980/10000 (10%)\n",
      "\n",
      "======Sigmoid======\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.313008\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 2.304617\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 2.307873\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 2.314577\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 2.305372\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 2.309309\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 2.303118\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 2.292203\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 2.302559\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 2.310912\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 2.310875\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 2.300566\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 2.305469\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 2.306996\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 2.311753\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 2.305719\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 2.295693\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 2.307152\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 2.312585\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 2.304177\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 2.296391\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 2.303787\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 2.305007\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 2.301284\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 2.304185\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 2.320790\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 2.309040\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 2.313697\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 2.295382\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 2.301946\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 2.312638\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 2.305226\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.300470\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 2.299055\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 2.310261\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 2.304342\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 2.303561\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 2.303556\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 2.311499\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 2.300709\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 2.308329\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 2.299953\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 2.312416\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 2.302490\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 2.306480\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 2.302099\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 2.298560\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 2.305745\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 2.313277\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 2.309347\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 2.302488\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 2.300509\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 2.304126\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 2.303221\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 2.297227\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 2.301990\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 2.311070\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 2.301305\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 2.310607\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 2.306035\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 980/10000 (10%)\n",
      "\n",
      "======Sigmoid======\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.309311\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 2.303591\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 2.308701\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 2.316526\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 2.303034\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 2.311713\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 2.309813\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 2.304730\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 2.307845\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 2.308566\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 2.299651\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 2.303140\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 2.300226\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 2.309067\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 2.317350\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 2.320865\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 2.313185\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 2.300731\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 2.298660\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 2.305239\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 2.307925\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 2.300046\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 2.306677\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 2.306245\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 2.313185\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 2.302276\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 2.312816\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 2.306832\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 2.306983\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 2.311087\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 2.305758\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 2.310955\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.300975\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 2.288447\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 2.312872\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 2.304647\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 2.307454\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 2.303423\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 2.311135\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 2.305716\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 2.308666\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 2.306064\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 2.309074\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 2.305399\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 2.315769\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 2.313844\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 2.305800\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 2.305077\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 2.305325\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 2.302552\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 2.309493\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 2.300609\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 2.303537\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 2.308560\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 2.301244\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 2.303773\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 2.305758\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 2.298759\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 2.308006\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 2.297837\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 980/10000 (10%)\n",
      "\n",
      "======Sigmoid======\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.303214\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 2.303326\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 2.309123\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 2.312807\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 2.310170\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 2.302129\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 2.312651\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 2.303184\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 2.310012\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 2.316587\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 2.300810\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 2.306882\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 2.308691\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 2.299914\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 2.305547\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 2.307464\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 2.308526\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 2.290322\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 2.310685\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 2.308809\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 2.305745\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 2.300382\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 2.299346\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 2.317751\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 2.303903\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 2.298245\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 2.304433\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 2.306174\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 2.313957\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 2.293433\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 2.313106\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 2.306117\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.300587\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 2.300105\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 2.307107\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 2.304523\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 2.305931\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 2.307889\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 2.314905\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 2.301284\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 2.301156\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 2.310026\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 2.310571\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 2.304903\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 2.302624\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 2.301808\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 2.307086\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 2.311725\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 2.299328\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 2.308649\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 2.299794\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 2.294357\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 2.316483\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 2.308706\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 2.313947\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 2.300966\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 2.301636\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 2.310181\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 2.303096\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 2.313612\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 980/10000 (10%)\n",
      "\n",
      "======Sigmoid======\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.309880\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 2.300582\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 2.307261\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 2.299555\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 2.307662\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 2.306708\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 2.302896\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 2.314806\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 2.302780\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 2.308899\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 2.293695\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 2.300103\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 2.304736\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 2.304789\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 2.294798\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 2.308381\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 2.296901\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 2.309703\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 2.314583\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 2.304292\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 2.309224\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 2.307282\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 2.306948\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 2.300484\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 2.304184\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 2.299499\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 2.307699\n",
      "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 2.310184\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 2.308049\n",
      "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 2.303806\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 2.307026\n",
      "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 2.300807\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.303959\n",
      "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 2.309139\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 2.307234\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 2.296293\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 2.302936\n",
      "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 2.305110\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 2.310861\n",
      "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 2.300833\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 2.299084\n",
      "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 2.309844\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 2.298657\n",
      "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 2.314576\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 2.309390\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 2.305860\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 2.301557\n",
      "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 2.322172\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 2.312041\n",
      "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 2.313187\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 2.307233\n",
      "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 2.296306\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 2.314057\n",
      "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 2.300500\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 2.307538\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 2.294499\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 2.305026\n",
      "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 2.306191\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 2.304497\n",
      "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 2.296151\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 980/10000 (10%)\n",
      "\n",
      "\n",
      "======tanh======\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.299449\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.306322\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.314031\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.325886\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.338658\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.317520\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.301248\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.305727\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.324229\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.298660\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.313395\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 2.308232\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.318493\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 2.315382\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.311589\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.338631\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.328636\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 2.331105\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.317408\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 2.321101\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.306324\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 2.310037\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 2.309776\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 2.307683\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.330487\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.273819\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 2.300105\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 2.322907\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 2.335316\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 2.327738\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.312910\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 2.296219\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.341363\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 2.314251\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 2.295826\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.316159\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 2.328019\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 2.310583\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 2.320617\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 2.300245\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.312856\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 2.308021\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 2.315059\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 2.308344\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 2.313821\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.298540\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 2.319807\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 2.281549\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.332026\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 2.305476\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.314693\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 2.316218\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 2.287187\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 2.316705\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 2.334100\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.322631\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 2.329591\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 2.304300\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 2.323021\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 2.299779\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "======tanh======\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.300285\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 2.287144\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 2.312950\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 2.302666\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 2.321762\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 2.304238\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 2.284570\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 2.304457\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 2.305121\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 2.305663\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.325419\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 2.290948\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 2.293308\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 2.311249\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 2.297873\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 2.290597\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.303939\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 2.285324\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 2.325576\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 2.308004\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.333978\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 2.329253\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 2.288929\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 2.306605\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 2.303911\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 2.321942\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 2.296150\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 2.332153\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 2.304765\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 2.312851\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.340161\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 2.285800\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.324611\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 2.301841\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 2.312685\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 2.315254\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 2.295484\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 2.305117\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 2.310222\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 2.328106\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.293209\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 2.317099\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 2.314662\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 2.322819\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 2.323730\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 2.310716\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 2.307459\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 2.326974\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 2.308031\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 2.312665\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 2.299086\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 2.304893\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 2.318218\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 2.306994\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 2.309543\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 2.319891\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 2.298143\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 2.300469\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 2.303213\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 2.313632\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "======tanh======\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.321983\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 2.325428\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 2.319573\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 2.297640\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 2.321958\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 2.331142\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 2.309170\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 2.299323\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 2.310669\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 2.326719\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 2.313171\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 2.311414\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 2.300816\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 2.316194\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 2.325387\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 2.307987\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 2.307463\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 2.294795\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 2.293282\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 2.269888\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 2.315858\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 2.314873\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 2.316166\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 2.324370\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 2.287104\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 2.308831\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 2.297259\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 2.308419\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 2.310838\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 2.299869\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 2.308101\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 2.297383\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.340592\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 2.319265\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 2.318179\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 2.314482\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 2.286458\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 2.303703\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 2.305164\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 2.327509\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 2.310362\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 2.340301\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 2.310241\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 2.327468\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 2.276277\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 2.333533\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 2.277107\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 2.303379\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 2.303067\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 2.326604\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 2.310522\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 2.298300\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 2.330723\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 2.321685\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 2.329204\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 2.313356\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 2.298330\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 2.314978\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 2.303641\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 2.319433\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "======tanh======\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.270925\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 2.297783\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 2.333443\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 2.289079\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 2.328943\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 2.290257\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 2.319371\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 2.331470\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 2.330021\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 2.311679\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 2.325991\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 2.307674\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 2.304691\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 2.309415\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 2.325005\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 2.303770\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 2.330276\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 2.304578\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 2.304204\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 2.297405\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 2.308219\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 2.312929\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 2.309146\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 2.315228\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 2.303915\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 2.301551\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 2.294671\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 2.318426\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 2.305698\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 2.294844\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 2.291811\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 2.317584\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.328064\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 2.298677\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 2.280413\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 2.307075\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 2.329450\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 2.311856\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 2.306539\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 2.296622\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 2.321175\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 2.312076\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 2.315109\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 2.328486\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 2.320027\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 2.341551\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 2.317050\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 2.324911\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 2.321951\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 2.326178\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 2.308805\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 2.300025\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 2.322789\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 2.345937\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 2.331815\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 2.299802\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 2.304566\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 2.289449\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 2.301697\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 2.319777\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "======tanh======\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.321064\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 2.330097\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 2.307716\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 2.304916\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 2.308844\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 2.294751\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 2.312403\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 2.309248\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 2.305296\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 2.310630\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 2.314029\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 2.309707\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 2.300074\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 2.283563\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 2.312058\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 2.321067\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 2.294037\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 2.307565\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 2.312623\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 2.304966\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 2.329351\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 2.303297\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 2.311441\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 2.307801\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 2.306092\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 2.301664\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 2.320416\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 2.317186\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 2.314900\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 2.302355\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 2.342677\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 2.318220\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.287400\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 2.322497\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 2.294455\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 2.313918\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 2.321289\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 2.303796\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 2.296021\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 2.307580\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 2.303099\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 2.291060\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 2.312037\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 2.326144\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 2.312078\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 2.336549\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 2.285793\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 2.303698\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 2.305017\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 2.329163\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 2.318596\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 2.309595\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 2.309678\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 2.303328\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 2.287553\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 2.312372\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 2.292271\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 2.310344\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 2.310236\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 2.339693\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "======tanh======\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.296902\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 2.288125\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 2.310928\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 2.306640\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 2.303567\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 2.301597\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 2.317036\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 2.272331\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 2.322721\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 2.302292\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 2.325381\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 2.288149\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 2.292092\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 2.317155\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 2.303244\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 2.317199\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 2.291593\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 2.293367\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 2.323510\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 2.307649\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 2.293217\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 2.314183\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 2.332855\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 2.342992\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 2.309420\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 2.298954\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 2.295823\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 2.300536\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 2.321462\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 2.301732\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 2.291924\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 2.289246\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.303506\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 2.330914\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 2.308112\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 2.319654\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 2.299274\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 2.328806\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 2.284503\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 2.316749\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 2.332390\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 2.322395\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 2.298820\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 2.300086\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 2.320966\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 2.311423\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 2.333071\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 2.301426\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 2.328388\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 2.299208\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 2.296124\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 2.340010\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 2.307425\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 2.290084\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 2.311976\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 2.333091\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 2.302981\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 2.310742\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 2.290718\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 2.305720\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "======tanh======\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.283235\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 2.323839\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 2.300854\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 2.311569\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 2.303488\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 2.309385\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 2.319615\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 2.303023\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 2.312769\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 2.321409\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 2.303797\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 2.317584\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 2.304897\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 2.314393\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 2.307434\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 2.292014\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 2.290109\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 2.315391\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 2.296950\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 2.331569\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 2.307081\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 2.313843\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 2.318415\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 2.294915\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 2.292169\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 2.315857\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 2.277056\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 2.322629\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 2.320309\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 2.300815\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 2.302631\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 2.291927\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.336235\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 2.312882\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 2.306307\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 2.317048\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 2.281121\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 2.312982\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 2.311010\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 2.321940\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 2.312373\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 2.310592\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 2.301506\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 2.300488\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 2.300783\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 2.313616\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 2.323806\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 2.336993\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 2.320404\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 2.309517\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 2.330959\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 2.290833\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 2.305407\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 2.321143\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 2.297756\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 2.310707\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 2.330860\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 2.320899\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 2.303821\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 2.299170\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "======tanh======\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.295688\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 2.314421\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 2.289023\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 2.325621\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 2.318518\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 2.292548\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 2.309769\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 2.311245\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 2.319793\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 2.314433\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 2.290786\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 2.278414\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 2.310444\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 2.331805\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 2.323980\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 2.306199\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 2.325898\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 2.327175\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 2.322835\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 2.312521\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 2.298913\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 2.312143\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 2.292115\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 2.293238\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 2.293760\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 2.313630\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 2.308715\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 2.316029\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 2.294581\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 2.300501\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 2.325531\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 2.286910\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.341178\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 2.320376\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 2.313403\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 2.323491\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 2.289757\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 2.282764\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 2.324393\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 2.313846\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 2.313612\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 2.301132\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 2.290995\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 2.303615\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 2.309597\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 2.301765\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 2.311543\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 2.291438\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 2.315769\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 2.322482\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 2.314774\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 2.322868\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 2.313256\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 2.301916\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 2.290134\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 2.302773\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 2.309685\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 2.315607\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 2.289559\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 2.338405\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "======tanh======\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.324048\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 2.312695\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 2.315695\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 2.318837\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 2.301407\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 2.297950\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 2.310505\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 2.286790\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 2.289167\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 2.299694\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 2.310841\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 2.316288\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 2.307423\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 2.325967\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 2.308558\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 2.306365\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 2.324470\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 2.304046\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 2.311374\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 2.315348\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 2.328473\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 2.321978\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 2.306449\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 2.288152\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 2.303803\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 2.305302\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 2.322539\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 2.290548\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 2.295298\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 2.337393\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 2.315140\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 2.326736\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.284056\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 2.323352\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 2.306038\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 2.304810\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 2.307106\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 2.325807\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 2.306590\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 2.288297\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 2.303367\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 2.321013\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 2.272406\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 2.312287\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 2.332228\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 2.325916\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 2.281002\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 2.303530\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 2.296998\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 2.290370\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 2.291176\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 2.317298\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 2.301091\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 2.291259\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 2.322730\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 2.287365\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 2.271398\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 2.309920\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 2.300531\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 2.303320\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "======tanh======\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.322521\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 2.299117\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 2.309868\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 2.323013\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 2.327479\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 2.316835\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 2.317304\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 2.297127\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 2.335452\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 2.328779\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 2.315840\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 2.328377\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 2.316087\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 2.298256\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 2.290291\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 2.299665\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 2.323102\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 2.328965\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 2.313643\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 2.321025\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 2.277530\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 2.291042\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 2.306443\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 2.328503\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 2.312175\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 2.328832\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 2.320245\n",
      "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 2.318650\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 2.312413\n",
      "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 2.317393\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 2.310609\n",
      "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 2.312005\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.290928\n",
      "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 2.306882\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 2.302907\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 2.313944\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 2.286826\n",
      "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 2.323860\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 2.312608\n",
      "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 2.306469\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 2.295923\n",
      "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 2.312301\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 2.330850\n",
      "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 2.312266\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 2.300126\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 2.327067\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 2.326647\n",
      "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 2.308474\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 2.316651\n",
      "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 2.311409\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 2.321941\n",
      "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 2.318719\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 2.275103\n",
      "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 2.290741\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 2.305735\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 2.315161\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 2.312526\n",
      "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 2.313963\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 2.321942\n",
      "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 2.323035\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "\n",
      "======ReLU======\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300189\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.311559\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.311091\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.311403\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.299278\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.305120\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.306934\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.299105\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.312419\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.322131\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.315882\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 2.310062\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.306160\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 2.308923\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.300659\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.312749\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.308368\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 2.317815\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.315442\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 2.306265\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.307606\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 2.307025\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 2.299498\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 2.311637\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.305274\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.314281\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 2.307058\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 2.297501\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 2.302556\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 2.311430\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.301169\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 2.313626\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.317575\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 2.300980\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 2.308791\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.313854\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 2.313953\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 2.309579\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 2.312817\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 2.306789\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.308935\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 2.309709\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 2.309571\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 2.307661\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 2.320827\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.301687\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 2.317593\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 2.317169\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.310439\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 2.309440\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.312357\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 2.304074\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 2.318760\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 2.297579\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 2.301812\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.312043\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 2.316946\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 2.315012\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 2.312391\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 2.314706\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1109/10000 (11%)\n",
      "\n",
      "======ReLU======\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.312876\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 2.318081\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 2.314065\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 2.305059\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 2.311875\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 2.315786\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 2.302328\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 2.319307\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 2.307045\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 2.305789\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.305575\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 2.312494\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 2.315557\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 2.315382\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 2.306848\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 2.306187\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.303166\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 2.312664\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 2.309168\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 2.308791\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.311170\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 2.310956\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 2.307091\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 2.306287\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 2.306234\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 2.311055\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 2.302882\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 2.317632\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 2.302867\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 2.300110\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.315829\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 2.294858\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.300404\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 2.308379\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 2.304008\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 2.305636\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 2.309658\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 2.306359\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 2.312641\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 2.305527\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.308868\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 2.324137\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 2.314563\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 2.312904\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 2.304560\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 2.301042\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 2.308955\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 2.302598\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 2.312988\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 2.313679\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 2.312231\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 2.319734\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 2.309085\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 2.318597\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 2.301861\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 2.319609\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 2.309023\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 2.317276\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 2.319576\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 2.310756\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1109/10000 (11%)\n",
      "\n",
      "======ReLU======\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.313905\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 2.304656\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 2.311758\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 2.315646\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 2.314273\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 2.319809\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 2.317537\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 2.306786\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 2.310085\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 2.302952\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 2.312512\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 2.297427\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 2.307448\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 2.305459\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 2.304035\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 2.313454\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 2.317960\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 2.305881\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 2.301876\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 2.306390\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 2.309680\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 2.316213\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 2.312445\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 2.304833\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 2.302281\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 2.310415\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 2.312821\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 2.308833\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 2.321028\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 2.305944\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 2.300245\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 2.303956\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.321010\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 2.313846\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 2.306414\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 2.302283\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 2.309916\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 2.307511\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 2.318108\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 2.304681\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 2.322290\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 2.303399\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 2.304792\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 2.297304\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 2.310208\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 2.309719\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 2.313587\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 2.301692\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 2.310570\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 2.309974\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 2.309354\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 2.312427\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 2.310615\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 2.305159\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 2.304107\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 2.322102\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 2.318688\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 2.312105\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 2.311508\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 2.305723\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1109/10000 (11%)\n",
      "\n",
      "======ReLU======\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.301086\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 2.311140\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 2.308424\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 2.313581\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 2.319295\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 2.311878\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 2.308228\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 2.301846\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 2.314514\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 2.310669\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 2.318373\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 2.303560\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 2.307728\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 2.313940\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 2.309854\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 2.311020\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 2.307564\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 2.317594\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 2.307647\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 2.316419\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 2.308138\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 2.311320\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 2.309431\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 2.302348\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 2.309808\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 2.318571\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 2.317429\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 2.305773\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 2.309403\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 2.302977\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 2.310444\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 2.299426\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.306963\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 2.300488\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 2.312588\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 2.307253\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 2.317450\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 2.306560\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 2.316325\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 2.316045\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 2.305902\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 2.311630\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 2.301092\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 2.318172\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 2.320838\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 2.304654\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 2.314620\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 2.310198\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 2.307292\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 2.311255\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 2.310764\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 2.305646\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 2.312159\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 2.306173\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 2.303766\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 2.319153\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 2.299636\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 2.313899\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 2.311848\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 2.312064\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1109/10000 (11%)\n",
      "\n",
      "======ReLU======\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.319002\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 2.305255\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 2.311838\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 2.305136\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 2.303993\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 2.294859\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 2.304250\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 2.297181\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 2.309310\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 2.311783\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 2.306306\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 2.309400\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 2.312762\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 2.305818\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 2.309832\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 2.305591\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 2.304770\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 2.311641\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 2.311081\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 2.314804\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 2.308002\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 2.307411\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 2.296143\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 2.315433\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 2.309131\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 2.308371\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 2.311022\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 2.298764\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 2.298117\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 2.310819\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 2.310782\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 2.311095\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.314511\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 2.317238\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 2.294595\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 2.302259\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 2.292692\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 2.299978\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 2.314951\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 2.318605\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 2.317866\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 2.309312\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 2.314259\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 2.305020\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 2.307028\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 2.315402\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 2.311576\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 2.299061\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 2.306068\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 2.310060\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 2.294983\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 2.310491\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 2.317115\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 2.310082\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 2.316028\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 2.292717\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 2.307710\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 2.320824\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 2.311262\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 2.310848\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1109/10000 (11%)\n",
      "\n",
      "======ReLU======\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.314016\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 2.314041\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 2.303939\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 2.297550\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 2.311300\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 2.311990\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 2.318849\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 2.309588\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 2.304126\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 2.303645\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 2.299113\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 2.300233\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 2.307150\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 2.313320\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 2.310767\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 2.319607\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 2.305467\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 2.316199\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 2.311611\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 2.310120\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 2.300601\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 2.302750\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 2.309093\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 2.301758\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 2.317294\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 2.312492\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 2.308497\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 2.306784\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 2.314302\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 2.318779\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 2.297400\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 2.304208\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.307116\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 2.302343\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 2.311002\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 2.307063\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 2.313797\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 2.311689\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 2.315543\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 2.308998\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 2.304162\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 2.316373\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 2.305190\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 2.312597\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 2.298564\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 2.315845\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 2.310222\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 2.303638\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 2.307204\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 2.310104\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 2.312049\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 2.318526\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 2.317291\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 2.325719\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 2.311577\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 2.313345\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 2.312729\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 2.314202\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 2.315462\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 2.306779\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1109/10000 (11%)\n",
      "\n",
      "======ReLU======\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.304202\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 2.305196\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 2.311465\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 2.300208\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 2.300827\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 2.306510\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 2.312113\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 2.311249\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 2.308650\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 2.301593\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 2.312240\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 2.309295\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 2.319817\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 2.306951\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 2.309995\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 2.304405\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 2.313264\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 2.303992\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 2.304251\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 2.303241\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 2.307007\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 2.306326\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 2.311038\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 2.308210\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 2.311433\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 2.308747\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 2.318168\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 2.304134\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 2.316695\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 2.305955\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 2.310122\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 2.315764\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.310675\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 2.316023\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 2.311067\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 2.297751\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 2.313054\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 2.316610\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 2.305992\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 2.307681\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 2.308868\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 2.308840\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 2.308192\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 2.308170\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 2.304701\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 2.308848\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 2.304697\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 2.322744\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 2.315717\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 2.304396\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 2.304013\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 2.312065\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 2.301821\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 2.307682\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 2.303283\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 2.321018\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 2.305465\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 2.315089\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 2.302575\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 2.312219\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1109/10000 (11%)\n",
      "\n",
      "======ReLU======\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.305868\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 2.304130\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 2.311716\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 2.308903\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 2.308577\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 2.312693\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 2.297029\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 2.306231\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 2.314247\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 2.307454\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 2.306320\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 2.311577\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 2.307024\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 2.304893\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 2.301167\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 2.305353\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 2.307549\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 2.318148\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 2.308598\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 2.319937\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 2.320940\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 2.317409\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 2.309560\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 2.305460\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 2.309584\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 2.315261\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 2.312251\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 2.314362\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 2.306767\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 2.305162\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 2.317639\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 2.305271\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.305940\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 2.300536\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 2.304626\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 2.314439\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 2.309634\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 2.319563\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 2.313731\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 2.300511\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 2.307342\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 2.303143\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 2.300117\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 2.301680\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 2.316477\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 2.305457\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 2.314637\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 2.316223\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 2.303723\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 2.305243\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 2.314379\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 2.303265\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 2.315624\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 2.298727\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 2.309017\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 2.303539\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 2.310894\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 2.298613\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 2.306408\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 2.300069\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1109/10000 (11%)\n",
      "\n",
      "======ReLU======\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.307404\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 2.310574\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 2.313570\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 2.304988\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 2.303262\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 2.309821\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 2.319394\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 2.304881\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 2.322563\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 2.310912\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 2.301886\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 2.306165\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 2.300204\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 2.299100\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 2.306882\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 2.310892\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 2.307680\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 2.312110\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 2.309663\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 2.302334\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 2.310944\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 2.304901\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 2.323463\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 2.305203\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 2.318764\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 2.288993\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 2.309082\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 2.305933\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 2.312513\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 2.305567\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 2.303715\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 2.306677\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.309910\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 2.315334\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 2.307344\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 2.310310\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 2.314091\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 2.303567\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 2.308424\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 2.300610\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 2.306856\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 2.304621\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 2.313414\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 2.307507\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 2.305428\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 2.310376\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 2.303916\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 2.303608\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 2.311324\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 2.305815\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 2.310833\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 2.314216\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 2.317549\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 2.310652\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 2.311224\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 2.316252\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 2.319469\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 2.307683\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 2.306362\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 2.309019\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1109/10000 (11%)\n",
      "\n",
      "======ReLU======\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.308701\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 2.309004\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 2.317453\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 2.310439\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 2.322889\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 2.316534\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 2.308898\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 2.313888\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 2.301299\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 2.317918\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 2.315531\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 2.310180\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 2.309512\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 2.306554\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 2.303614\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 2.321116\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 2.310884\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 2.313153\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 2.307326\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 2.314376\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 2.301598\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 2.315269\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 2.315985\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 2.309575\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 2.320665\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 2.313262\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 2.311220\n",
      "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 2.308352\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 2.302490\n",
      "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 2.300245\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 2.307872\n",
      "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 2.315348\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.303525\n",
      "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 2.303406\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 2.298342\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 2.306136\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 2.302234\n",
      "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 2.310084\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 2.298064\n",
      "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 2.305937\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 2.294103\n",
      "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 2.311595\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 2.310966\n",
      "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 2.311023\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 2.302469\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 2.306543\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 2.319667\n",
      "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 2.319406\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 2.315836\n",
      "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 2.302758\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 2.317789\n",
      "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 2.314822\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 2.299932\n",
      "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 2.304506\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 2.302078\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 2.299729\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 2.307458\n",
      "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 2.320302\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 2.302535\n",
      "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 2.304860\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1109/10000 (11%)\n",
      "\n",
      "\n",
      "======Leaky ReLU======\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307920\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.306707\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.295137\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.309775\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.300221\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.309023\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.311921\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.302118\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.299420\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.310756\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.306391\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 2.304547\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.308820\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 2.309800\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.311773\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.308803\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.307660\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 2.301288\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.304411\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 2.297549\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.305906\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 2.309504\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 2.306350\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 2.297709\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.307638\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.301888\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 2.304739\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 2.316363\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 2.306600\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 2.307445\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.312492\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 2.301807\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.306651\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 2.307698\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 2.309524\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.306663\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 2.300469\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 2.305345\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 2.308123\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 2.301019\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.310944\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 2.307386\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 2.313217\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 2.302590\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 2.300928\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.314355\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 2.306956\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 2.303209\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.306317\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 2.306396\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.315665\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 2.308777\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 2.310630\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 2.315612\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 2.303719\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.311865\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 2.312524\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 2.306934\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 2.313795\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 2.308070\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1024/10000 (10%)\n",
      "\n",
      "======Leaky ReLU======\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.304264\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 2.307126\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 2.308214\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 2.311294\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 2.301993\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 2.305957\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 2.313389\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 2.304682\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 2.306063\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 2.313398\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.309327\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 2.302857\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 2.313179\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 2.302962\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 2.317377\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 2.309744\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.307552\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 2.309594\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 2.307502\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 2.313997\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.313122\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 2.311944\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 2.297430\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 2.310885\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 2.305560\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 2.309064\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 2.303615\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 2.307983\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 2.313094\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 2.303529\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.314730\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 2.312335\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.313177\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 2.308088\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 2.309238\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 2.302676\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 2.305281\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 2.309196\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 2.302933\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 2.306451\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.311255\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 2.303802\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 2.316933\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 2.308690\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 2.308284\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 2.305229\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 2.314479\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 2.311880\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 2.313659\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 2.313425\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 2.307569\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 2.316465\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 2.296624\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 2.302958\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 2.311533\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 2.310344\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 2.319379\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 2.306562\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 2.312163\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 2.306160\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1024/10000 (10%)\n",
      "\n",
      "======Leaky ReLU======\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.305170\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 2.312820\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 2.308029\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 2.306786\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 2.313459\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 2.306567\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 2.302328\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 2.306027\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 2.305482\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 2.306012\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 2.303614\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 2.309947\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 2.314412\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 2.307314\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 2.304635\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 2.311278\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 2.310141\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 2.311372\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 2.307364\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 2.307533\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 2.313289\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 2.314429\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 2.313540\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 2.310009\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 2.309315\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 2.301946\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 2.307367\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 2.304563\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 2.302453\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 2.310850\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 2.310591\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 2.303791\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.313787\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 2.309349\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 2.309408\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 2.313497\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 2.307168\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 2.298130\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 2.314484\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 2.306631\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 2.306560\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 2.304842\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 2.309614\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 2.305471\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 2.306798\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 2.310696\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 2.308908\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 2.311326\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 2.301390\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 2.313471\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 2.302186\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 2.298776\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 2.310705\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 2.304697\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 2.306205\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 2.307119\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 2.306658\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 2.306099\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 2.303388\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 2.302888\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1024/10000 (10%)\n",
      "\n",
      "======Leaky ReLU======\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.311279\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 2.294226\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 2.302389\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 2.309496\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 2.304597\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 2.307349\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 2.309258\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 2.306997\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 2.311559\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 2.306543\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 2.307231\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 2.301140\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 2.308391\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 2.305032\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 2.304891\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 2.308751\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 2.311448\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 2.308788\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 2.315461\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 2.310224\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 2.317181\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 2.307735\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 2.310200\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 2.301681\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 2.306939\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 2.316071\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 2.308205\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 2.301257\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 2.307730\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 2.304440\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 2.314531\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 2.306473\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.306919\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 2.308945\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 2.308302\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 2.306091\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 2.313375\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 2.317540\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 2.308180\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 2.300328\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 2.312530\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 2.306789\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 2.305476\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 2.300745\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 2.307585\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 2.309797\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 2.307187\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 2.304770\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 2.314094\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 2.307329\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 2.313309\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 2.313870\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 2.304279\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 2.305100\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 2.309002\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 2.314406\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 2.307386\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 2.311790\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 2.305279\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 2.311152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1024/10000 (10%)\n",
      "\n",
      "======Leaky ReLU======\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.311643\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 2.318044\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 2.307958\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 2.305193\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 2.306368\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 2.312163\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 2.304032\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 2.303032\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 2.309253\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 2.305544\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 2.307915\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 2.306134\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 2.308336\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 2.314509\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 2.304612\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 2.304080\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 2.303126\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 2.310402\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 2.306400\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 2.312750\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 2.314993\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 2.304480\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 2.304505\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 2.311617\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 2.311521\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 2.304723\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 2.308076\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 2.311998\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 2.302422\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 2.314971\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 2.309237\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 2.312234\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.303746\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 2.316042\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 2.311276\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 2.304286\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 2.310664\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 2.307877\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 2.315377\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 2.307719\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 2.306645\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 2.313664\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 2.311704\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 2.310339\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 2.308934\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 2.300566\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 2.311088\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 2.304398\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 2.307269\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 2.301086\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 2.312424\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 2.310761\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 2.312450\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 2.305963\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 2.299645\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 2.301201\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 2.315271\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 2.310234\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 2.310696\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 2.314237\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1024/10000 (10%)\n",
      "\n",
      "======Leaky ReLU======\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.307977\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 2.314219\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 2.312434\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 2.284995\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 2.318515\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 2.315859\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 2.310647\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 2.307635\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 2.306936\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 2.312085\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 2.303313\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 2.309397\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 2.303830\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 2.314345\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 2.303771\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 2.310869\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 2.314338\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 2.313350\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 2.307261\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 2.309076\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 2.311765\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 2.300126\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 2.309276\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 2.301457\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 2.307394\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 2.308244\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 2.314665\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 2.301450\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 2.308410\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 2.315013\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 2.307384\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 2.314260\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.304630\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 2.314118\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 2.301816\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 2.308157\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 2.310452\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 2.308814\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 2.315589\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 2.309328\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 2.311792\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 2.305351\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 2.307435\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 2.308173\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 2.311022\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 2.311244\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 2.312586\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 2.302274\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 2.312963\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 2.304508\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 2.314240\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 2.299787\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 2.312289\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 2.305232\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 2.304286\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 2.298346\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 2.305759\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 2.303088\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 2.306012\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 2.307080\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1024/10000 (10%)\n",
      "\n",
      "======Leaky ReLU======\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.313420\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 2.305745\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 2.300659\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 2.306588\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 2.314083\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 2.308460\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 2.311320\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 2.302597\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 2.304764\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 2.310864\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 2.303162\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 2.307826\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 2.312691\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 2.300149\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 2.303821\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 2.312316\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 2.308256\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 2.313331\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 2.300311\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 2.303211\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 2.310328\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 2.304396\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 2.308590\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 2.316395\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 2.309531\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 2.307476\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 2.305911\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 2.309722\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 2.311086\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 2.312768\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 2.306526\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 2.310503\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.303894\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 2.307276\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 2.308075\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 2.308270\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 2.305735\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 2.309968\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 2.315678\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 2.309082\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 2.313047\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 2.306749\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 2.302692\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 2.303701\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 2.302382\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 2.304260\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 2.310428\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 2.310143\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 2.309495\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 2.308191\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 2.307567\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 2.313436\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 2.305034\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 2.306749\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 2.302443\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 2.314098\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 2.309503\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 2.307474\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 2.306242\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 2.310060\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1024/10000 (10%)\n",
      "\n",
      "======Leaky ReLU======\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.306505\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 2.304209\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 2.308195\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 2.310622\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 2.307254\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 2.309573\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 2.310025\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 2.306373\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 2.304524\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 2.310983\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 2.309120\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 2.309925\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 2.307165\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 2.311720\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 2.307150\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 2.307806\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 2.312532\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 2.299161\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 2.307749\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 2.308132\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 2.302146\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 2.307613\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 2.310784\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 2.311471\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 2.303193\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 2.312163\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 2.309136\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 2.310489\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 2.307057\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 2.305029\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 2.306076\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 2.310249\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.294070\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 2.305136\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 2.298620\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 2.306890\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 2.311188\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 2.315921\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 2.309628\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 2.306285\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 2.307351\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 2.311552\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 2.307251\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 2.306769\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 2.307882\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 2.302687\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 2.304235\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 2.306701\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 2.304041\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 2.308099\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 2.309429\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 2.310143\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 2.309441\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 2.302791\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 2.310552\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 2.310062\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 2.305724\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 2.314441\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 2.311507\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 2.306629\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1024/10000 (10%)\n",
      "\n",
      "======Leaky ReLU======\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.303612\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 2.306940\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 2.306478\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 2.306959\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 2.310624\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 2.311356\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 2.308919\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 2.306777\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 2.300939\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 2.304431\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 2.296291\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 2.291592\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 2.314589\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 2.305001\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 2.307659\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 2.313916\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 2.304366\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 2.294685\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 2.304717\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 2.304742\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 2.307837\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 2.305984\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 2.302975\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 2.307202\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 2.309186\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 2.307203\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 2.313666\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 2.308350\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 2.310576\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 2.307465\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 2.314476\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 2.296988\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.315719\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 2.310985\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 2.307858\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 2.304072\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 2.304511\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 2.302547\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 2.305430\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 2.311291\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 2.314342\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 2.309030\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 2.313953\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 2.302093\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 2.306841\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 2.311537\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 2.303780\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 2.294913\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 2.304637\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 2.306042\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 2.305473\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 2.319248\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 2.307796\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 2.300466\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 2.306576\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 2.308074\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 2.312190\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 2.312893\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 2.308414\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 2.311572\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1024/10000 (10%)\n",
      "\n",
      "======Leaky ReLU======\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.309877\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 2.304157\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 2.309551\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 2.303338\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 2.307366\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 2.308398\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 2.308126\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 2.308073\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 2.308795\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 2.310464\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 2.309211\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 2.313331\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 2.302851\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 2.311549\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 2.296740\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 2.303588\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 2.309636\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 2.310671\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 2.308681\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 2.312476\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 2.303731\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 2.316006\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 2.309919\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 2.311376\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 2.306929\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 2.307534\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 2.307463\n",
      "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 2.316051\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 2.304080\n",
      "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 2.305794\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 2.299628\n",
      "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 2.306690\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.305957\n",
      "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 2.303252\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 2.306076\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 2.307442\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 2.307498\n",
      "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 2.307271\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 2.305123\n",
      "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 2.300487\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 2.301451\n",
      "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 2.316782\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 2.304818\n",
      "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 2.312067\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 2.312683\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 2.299751\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 2.304295\n",
      "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 2.305311\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 2.309517\n",
      "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 2.308508\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 2.312635\n",
      "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 2.311545\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 2.302254\n",
      "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 2.300653\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 2.310535\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 2.306120\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 2.305922\n",
      "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 2.311450\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 2.306501\n",
      "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 2.308195\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1024/10000 (10%)\n",
      "\n",
      "\n",
      "======ELU======\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.322921\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.315713\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.335889\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.292083\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.313163\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.308225\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.332288\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.302958\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.344629\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.321228\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.341302\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 2.310553\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.327211\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 2.297656\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.320033\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.328253\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.347257\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 2.311018\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.309932\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 2.336428\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.320431\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 2.310739\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 2.313003\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 2.321332\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.298705\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.299886\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 2.324440\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 2.354712\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 2.287771\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 2.315114\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.320321\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 2.314328\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.314671\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 2.310443\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 2.328886\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.301305\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 2.308723\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 2.329205\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 2.323221\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 2.298802\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.299125\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 2.346887\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 2.317459\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 2.299815\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 2.329596\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.310216\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 2.347199\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 2.313498\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.299161\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 2.316548\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.321617\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 2.337470\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 2.321318\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 2.328319\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 2.307840\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.321123\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 2.308323\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 2.325376\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 2.343677\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 2.329415\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 864/10000 (9%)\n",
      "\n",
      "======ELU======\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.318055\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 2.337721\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 2.312586\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 2.305496\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 2.306130\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 2.331137\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 2.292027\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 2.314101\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 2.322002\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 2.330302\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.294122\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 2.315995\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 2.298452\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 2.332228\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 2.316066\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 2.328411\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.330861\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 2.296504\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 2.302961\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 2.277009\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.319593\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 2.300734\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 2.328343\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 2.311578\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 2.351730\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 2.347044\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 2.306083\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 2.304825\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 2.289199\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 2.320590\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.295103\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 2.304692\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.310607\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 2.294544\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 2.310375\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 2.321811\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 2.308756\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 2.316851\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 2.316927\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 2.320495\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.310495\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 2.311287\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 2.335784\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 2.322391\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 2.313530\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 2.326953\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 2.331880\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 2.332322\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 2.318735\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 2.320112\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 2.275165\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 2.282312\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 2.300961\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 2.308677\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 2.308763\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 2.340009\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 2.345693\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 2.309669\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 2.339478\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 2.298250\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 864/10000 (9%)\n",
      "\n",
      "======ELU======\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.306673\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 2.332915\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 2.307147\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 2.298488\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 2.314500\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 2.335856\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 2.321101\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 2.297622\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 2.329716\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 2.302938\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 2.304276\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 2.311743\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 2.319380\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 2.323936\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 2.302994\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 2.308899\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 2.338805\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 2.301772\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 2.335053\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 2.321015\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 2.314852\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 2.326673\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 2.311351\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 2.312361\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 2.324697\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 2.329521\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 2.320986\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 2.332417\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 2.324324\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 2.326810\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 2.344176\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 2.300568\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.328842\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 2.314366\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 2.349193\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 2.290280\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 2.320461\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 2.316497\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 2.339437\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 2.335509\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 2.320347\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 2.308742\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 2.324811\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 2.319310\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 2.310481\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 2.300990\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 2.316380\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 2.319975\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 2.293955\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 2.328165\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 2.345452\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 2.311463\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 2.307410\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 2.314685\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 2.335090\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 2.304604\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 2.294577\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 2.325691\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 2.336148\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 2.306043\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 864/10000 (9%)\n",
      "\n",
      "======ELU======\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.324235\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 2.326702\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 2.316946\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 2.331694\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 2.363090\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 2.309464\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 2.307656\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 2.292365\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 2.340052\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 2.317149\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 2.323566\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 2.329737\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 2.341793\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 2.321612\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 2.292552\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 2.298428\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 2.327879\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 2.323033\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 2.346757\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 2.342452\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 2.306480\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 2.329502\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 2.327728\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 2.282974\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 2.332056\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 2.316582\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 2.317299\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 2.306274\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 2.330432\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 2.317229\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 2.331804\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 2.321865\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.327073\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 2.309261\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 2.322509\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 2.319916\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 2.305485\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 2.322440\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 2.356724\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 2.328778\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 2.361372\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 2.312232\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 2.314785\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 2.304407\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 2.315809\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 2.312775\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 2.306022\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 2.324468\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 2.311338\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 2.330520\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 2.341427\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 2.312330\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 2.309018\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 2.319003\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 2.306216\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 2.305893\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 2.314980\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 2.316694\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 2.313787\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 2.312979\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 864/10000 (9%)\n",
      "\n",
      "======ELU======\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.337946\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 2.324792\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 2.320145\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 2.324183\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 2.326599\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 2.323724\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 2.307478\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 2.316451\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 2.326528\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 2.322536\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 2.321974\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 2.316550\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 2.297675\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 2.315028\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 2.314294\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 2.301955\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 2.325201\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 2.312917\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 2.301798\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 2.322121\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 2.320132\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 2.328805\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 2.324579\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 2.322750\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 2.302091\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 2.318703\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 2.303030\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 2.316875\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 2.322063\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 2.309321\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 2.326748\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 2.297300\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.311951\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 2.311466\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 2.324221\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 2.321821\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 2.360456\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 2.328724\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 2.329214\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 2.284933\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 2.287510\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 2.322098\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 2.329642\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 2.324361\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 2.316787\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 2.329785\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 2.327627\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 2.288990\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 2.307297\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 2.310329\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 2.328953\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 2.299715\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 2.317431\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 2.361755\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 2.313291\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 2.318002\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 2.309198\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 2.317007\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 2.325018\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 2.323276\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 864/10000 (9%)\n",
      "\n",
      "======ELU======\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.314709\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 2.354158\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 2.303574\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 2.335740\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 2.345581\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 2.306433\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 2.336347\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 2.318022\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 2.334892\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 2.311306\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 2.310169\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 2.293341\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 2.317288\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 2.322799\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 2.338665\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 2.315612\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 2.345884\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 2.324070\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 2.320461\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 2.293231\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 2.307014\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 2.326411\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 2.319487\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 2.348380\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 2.305770\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 2.350225\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 2.311755\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 2.323723\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 2.336019\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 2.326465\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 2.301545\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 2.344515\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.325217\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 2.323216\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 2.331083\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 2.311756\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 2.318802\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 2.330730\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 2.326743\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 2.293034\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 2.343209\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 2.331136\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 2.311208\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 2.335516\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 2.300642\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 2.298550\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 2.347814\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 2.319313\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 2.327007\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 2.305802\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 2.323154\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 2.307371\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 2.290884\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 2.302241\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 2.301156\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 2.294560\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 2.317037\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 2.301335\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 2.310412\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 2.312806\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 864/10000 (9%)\n",
      "\n",
      "======ELU======\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.296093\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 2.330518\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 2.295495\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 2.313887\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 2.315893\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 2.311665\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 2.326699\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 2.300125\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 2.301835\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 2.324117\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 2.311137\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 2.346821\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 2.309899\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 2.326396\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 2.301844\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 2.315799\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 2.344867\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 2.294316\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 2.331528\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 2.314317\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 2.308145\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 2.332111\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 2.315160\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 2.325919\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 2.321262\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 2.322338\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 2.301721\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 2.318436\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 2.352409\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 2.321632\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 2.321062\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 2.282140\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.329667\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 2.322441\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 2.291624\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 2.315499\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 2.296632\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 2.303045\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 2.327497\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 2.310789\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 2.325600\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 2.311936\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 2.319108\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 2.345574\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 2.323429\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 2.329446\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 2.305266\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 2.319425\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 2.308809\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 2.310972\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 2.315520\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 2.318234\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 2.327732\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 2.317903\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 2.315779\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 2.291523\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 2.305564\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 2.323736\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 2.301990\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 2.312104\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 864/10000 (9%)\n",
      "\n",
      "======ELU======\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.317855\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 2.309811\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 2.310550\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 2.325541\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 2.316600\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 2.326403\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 2.313462\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 2.336942\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 2.332326\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 2.304184\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 2.332425\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 2.281731\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 2.313227\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 2.333791\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 2.295279\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 2.329059\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 2.320446\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 2.303140\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 2.327426\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 2.326223\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 2.306006\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 2.315699\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 2.302670\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 2.324169\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 2.311373\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 2.316552\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 2.306704\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 2.319094\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 2.338148\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 2.305182\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 2.322766\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 2.320006\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.321673\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 2.313351\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 2.328618\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 2.315717\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 2.324165\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 2.324597\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 2.302959\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 2.306527\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 2.338958\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 2.326004\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 2.312793\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 2.318015\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 2.355454\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 2.307284\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 2.313794\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 2.335732\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 2.310972\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 2.300333\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 2.328456\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 2.338400\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 2.307436\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 2.341237\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 2.316817\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 2.288637\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 2.311664\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 2.335775\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 2.335664\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 2.313794\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 864/10000 (9%)\n",
      "\n",
      "======ELU======\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.303609\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 2.328304\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 2.309319\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 2.338755\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 2.293740\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 2.316601\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 2.323548\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 2.323383\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 2.297838\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 2.291854\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 2.324338\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 2.337176\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 2.311485\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 2.323509\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 2.328283\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 2.292184\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 2.319860\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 2.320767\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 2.333474\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 2.317882\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 2.305983\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 2.335802\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 2.306480\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 2.310784\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 2.330513\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 2.328360\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 2.328783\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 2.341430\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 2.314588\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 2.309092\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 2.321379\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 2.297296\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.309344\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 2.327893\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 2.304391\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 2.323360\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 2.340328\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 2.313020\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 2.303400\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 2.336459\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 2.318566\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 2.325494\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 2.346915\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 2.322137\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 2.322819\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 2.317593\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 2.293998\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 2.296664\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 2.295801\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 2.309537\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 2.328364\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 2.328712\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 2.312544\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 2.316628\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 2.320434\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 2.315597\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 2.333519\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 2.306193\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 2.312840\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 2.303529\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 864/10000 (9%)\n",
      "\n",
      "======ELU======\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.308352\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 2.334101\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 2.321461\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 2.318147\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 2.306205\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 2.318055\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 2.316063\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 2.319361\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 2.355090\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 2.318600\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 2.332458\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 2.325887\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 2.308870\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 2.294036\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 2.324815\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 2.334086\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 2.326539\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 2.302040\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 2.311971\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 2.335331\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 2.332648\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 2.338784\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 2.327916\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 2.322121\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 2.316212\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 2.296631\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 2.297943\n",
      "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 2.321554\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 2.329343\n",
      "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 2.346405\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 2.316693\n",
      "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 2.318706\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.356949\n",
      "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 2.301552\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 2.282091\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 2.339096\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 2.321020\n",
      "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 2.317619\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 2.297602\n",
      "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 2.297062\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 2.332209\n",
      "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 2.318009\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 2.312603\n",
      "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 2.308079\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 2.331437\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 2.320926\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 2.318129\n",
      "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 2.291735\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 2.330380\n",
      "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 2.307337\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 2.327152\n",
      "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 2.340845\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 2.322947\n",
      "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 2.338040\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 2.326455\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 2.307704\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 2.326939\n",
      "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 2.319136\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 2.308650\n",
      "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 2.309351\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 864/10000 (9%)\n",
      "\n",
      "\n",
      "======softmax======\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302845\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.302926\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.302497\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.303159\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.303544\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.302432\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.302854\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.302793\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.302229\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.302643\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.302628\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 2.301936\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.301791\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 2.302459\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.302676\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.302722\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.302356\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 2.302434\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.302664\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 2.302564\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.302123\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 2.302392\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 2.301717\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 2.302881\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.302133\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.302643\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 2.302759\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 2.302804\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 2.303048\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 2.302863\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.302724\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 2.302559\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.301989\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 2.302456\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 2.302252\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 2.302278\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 2.302262\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 2.303206\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 2.302313\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.302899\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 2.301858\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 2.302745\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 2.302483\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 2.303035\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.302229\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 2.301795\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 2.302271\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.302366\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 2.302244\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.302658\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 2.302097\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 2.302591\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 2.303133\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 2.302897\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.302525\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 2.302142\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 2.302730\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 2.301818\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 2.302569\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 892/10000 (9%)\n",
      "\n",
      "======softmax======\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.303381\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 2.302683\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 2.301728\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 2.302671\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 2.302538\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 2.301851\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 2.302408\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 2.302227\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 2.302248\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 2.302357\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.302835\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 2.301754\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 2.302602\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 2.303241\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 2.302807\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 2.302939\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.302320\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 2.302365\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 2.302021\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 2.302995\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.302890\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 2.302825\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 2.302821\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 2.302994\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 2.302527\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 2.302812\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 2.303259\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 2.302869\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 2.302437\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 2.302723\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.302436\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 2.302540\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.302805\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 2.302284\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 2.301757\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 2.302705\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 2.302730\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 2.301573\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 2.302693\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 2.302568\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.302284\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 2.303257\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 2.302446\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 2.301946\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 2.303273\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 2.302455\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 2.303248\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 2.302610\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 2.302366\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 2.302941\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 2.302719\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 2.302350\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 2.302156\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 2.302918\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 2.302625\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 2.302629\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 2.301812\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 2.302531\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 2.303613\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 2.302491\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 892/10000 (9%)\n",
      "\n",
      "======softmax======\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.302933\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 2.302224\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 2.302366\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 2.302055\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 2.302788\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 2.302570\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 2.302758\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 2.301889\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 2.302409\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 2.302981\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 2.302220\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 2.302352\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 2.301793\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 2.302471\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 2.303179\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 2.302283\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 2.302717\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 2.303300\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 2.302778\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 2.302629\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 2.302813\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 2.302059\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 2.302911\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 2.302668\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 2.302874\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 2.302608\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 2.302941\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 2.302944\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 2.302078\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 2.301662\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 2.302640\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 2.302844\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.302581\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 2.302646\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 2.302615\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 2.302693\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 2.302455\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 2.302406\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 2.303177\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 2.302159\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 2.302486\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 2.302663\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 2.302712\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 2.302390\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 2.302405\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 2.303104\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 2.302804\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 2.302906\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 2.301959\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 2.303198\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 2.303051\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 2.302801\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 2.302337\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 2.302764\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 2.303189\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 2.302237\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 2.302766\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 2.303152\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 2.303354\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 2.302780\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 892/10000 (9%)\n",
      "\n",
      "======softmax======\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.302973\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 2.302563\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 2.302116\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 2.302676\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 2.303140\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 2.302747\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 2.302755\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 2.302689\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 2.302303\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 2.302140\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 2.302841\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 2.302901\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 2.301949\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 2.302564\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 2.302572\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 2.301616\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 2.303113\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 2.303480\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 2.302296\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 2.302008\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 2.302854\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 2.302152\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 2.303584\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 2.302860\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 2.302579\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 2.302143\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 2.302381\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 2.303201\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 2.302734\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 2.302986\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 2.302380\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 2.302265\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.302938\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 2.302997\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 2.302624\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 2.303129\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 2.301475\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 2.302792\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 2.302430\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 2.302904\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 2.303134\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 2.303222\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 2.302785\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 2.302537\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 2.302204\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 2.302313\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 2.302519\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 2.302541\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 2.302852\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 2.302434\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 2.302765\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 2.302978\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 2.303135\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 2.302802\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 2.302719\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 2.302567\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 2.303186\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 2.302567\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 2.302900\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 2.302703\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 892/10000 (9%)\n",
      "\n",
      "======softmax======\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.303557\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 2.302418\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 2.302379\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 2.302811\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 2.302187\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 2.303149\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 2.302169\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 2.302860\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 2.302926\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 2.302356\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 2.302299\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 2.302465\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 2.302050\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 2.302191\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 2.302359\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 2.302079\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 2.303310\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 2.302606\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 2.302342\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 2.301981\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 2.302808\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 2.302006\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 2.303144\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 2.303090\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 2.302282\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 2.302713\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 2.302866\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 2.302311\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 2.303229\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 2.302474\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 2.302249\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 2.302150\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.302457\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 2.302493\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 2.302380\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 2.302587\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 2.302422\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 2.302763\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 2.303175\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 2.303112\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 2.302658\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 2.302725\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 2.303191\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 2.302811\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 2.302764\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 2.301959\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 2.302372\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 2.302792\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 2.302060\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 2.302920\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 2.303283\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 2.302593\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 2.302672\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 2.301725\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 2.303005\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 2.302480\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 2.303523\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 2.302170\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 2.302548\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 2.303424\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 892/10000 (9%)\n",
      "\n",
      "======softmax======\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.302378\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 2.302685\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 2.301671\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 2.302803\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 2.302733\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 2.302622\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 2.302516\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 2.302478\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 2.302960\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 2.302841\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 2.302361\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 2.302370\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 2.302727\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 2.302810\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 2.302593\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 2.302348\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 2.302716\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 2.302308\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 2.302851\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 2.302459\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 2.302815\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 2.303105\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 2.302233\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 2.302334\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 2.302778\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 2.302830\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 2.302507\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 2.303253\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 2.302470\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 2.302667\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 2.302354\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 2.302440\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.302971\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 2.302931\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 2.302899\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 2.302204\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 2.302647\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 2.302356\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 2.302224\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 2.301510\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 2.302164\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 2.302854\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 2.302448\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 2.302581\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 2.302720\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 2.302869\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 2.302789\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 2.302986\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 2.301971\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 2.302580\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 2.302773\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 2.303225\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 2.302758\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 2.303620\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 2.303112\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 2.303597\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 2.302423\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 2.302720\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 2.303224\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 2.303110\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 892/10000 (9%)\n",
      "\n",
      "======softmax======\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.303202\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 2.303118\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 2.302717\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 2.302805\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 2.302423\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 2.302549\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 2.302635\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 2.303154\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 2.303470\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 2.303505\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 2.302589\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 2.303055\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 2.302818\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 2.302311\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 2.301935\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 2.301948\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 2.302660\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 2.302403\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 2.302741\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 2.302996\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 2.302818\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 2.303152\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 2.301104\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 2.301839\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 2.302691\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 2.302209\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 2.302703\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 2.302685\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 2.302938\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 2.302804\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 2.302940\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 2.302311\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.302215\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 2.302417\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 2.302075\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 2.302398\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 2.302290\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 2.302128\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 2.302600\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 2.301624\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 2.302777\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 2.302336\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 2.302490\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 2.303463\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 2.302045\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 2.302496\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 2.302257\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 2.302025\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 2.302117\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 2.302629\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 2.303024\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 2.302174\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 2.302582\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 2.303054\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 2.303415\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 2.302279\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 2.302962\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 2.302471\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 2.302583\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 2.302201\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 892/10000 (9%)\n",
      "\n",
      "======softmax======\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.302606\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 2.302699\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 2.302968\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 2.302764\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 2.302129\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 2.302788\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 2.302606\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 2.303238\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 2.302950\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 2.301734\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 2.302723\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 2.302806\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 2.302749\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 2.302384\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 2.302125\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 2.302825\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 2.302997\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 2.302842\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 2.303159\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 2.302407\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 2.302532\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 2.302605\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 2.303195\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 2.302774\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 2.302943\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 2.302547\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 2.302072\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 2.302614\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 2.302941\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 2.302555\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 2.303349\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 2.302845\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.303478\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 2.302210\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 2.302683\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 2.302252\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 2.301744\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 2.302981\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 2.303125\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 2.301537\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 2.302120\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 2.303354\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 2.303195\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 2.302657\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 2.302394\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 2.302073\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 2.303120\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 2.302487\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 2.303417\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 2.302598\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 2.302774\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 2.302619\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 2.302518\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 2.302061\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 2.303001\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 2.302608\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 2.302670\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 2.302100\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 2.302994\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 2.302856\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 892/10000 (9%)\n",
      "\n",
      "======softmax======\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.302012\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 2.302301\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 2.303364\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 2.302429\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 2.303205\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 2.302832\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 2.302802\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 2.302864\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 2.302704\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 2.302045\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 2.302932\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 2.302768\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 2.302963\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 2.301901\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 2.303194\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 2.302568\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 2.302926\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 2.302252\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 2.302797\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 2.302345\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 2.301910\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 2.302849\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 2.302045\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 2.302403\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 2.302748\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 2.303118\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 2.302362\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 2.302505\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 2.301981\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 2.302588\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 2.302239\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 2.303495\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.303538\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 2.302144\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 2.302849\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 2.302871\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 2.302349\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 2.302989\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 2.302285\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 2.303309\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 2.302431\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 2.303476\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 2.302076\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 2.302841\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 2.302614\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 2.301994\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 2.302785\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 2.302410\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 2.302903\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 2.302898\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 2.301816\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 2.302120\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 2.302356\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 2.302573\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 2.302868\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 2.302801\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 2.302672\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 2.303394\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 2.302336\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 2.302832\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 892/10000 (9%)\n",
      "\n",
      "======softmax======\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.302272\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 2.302146\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 2.302998\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 2.302954\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 2.301901\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 2.302470\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 2.301700\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 2.302242\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 2.301610\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 2.302999\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 2.302142\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 2.301995\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 2.302608\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 2.302742\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 2.302041\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 2.302504\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 2.302339\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 2.303123\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 2.302541\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 2.302844\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 2.302957\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 2.302362\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 2.301859\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 2.302328\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 2.302405\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 2.302940\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 2.302281\n",
      "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 2.302255\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 2.302388\n",
      "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 2.302886\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 2.302969\n",
      "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 2.302495\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.302619\n",
      "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 2.302697\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 2.302213\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 2.302829\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 2.302958\n",
      "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 2.302642\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 2.303066\n",
      "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 2.302107\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 2.301971\n",
      "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 2.302465\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 2.302116\n",
      "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 2.302632\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 2.301783\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 2.302551\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 2.303210\n",
      "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 2.302606\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 2.302933\n",
      "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 2.302320\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 2.302367\n",
      "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 2.302398\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 2.302745\n",
      "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 2.302198\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 2.303011\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 2.302339\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 2.302710\n",
      "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 2.302558\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 2.303172\n",
      "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 2.302449\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 892/10000 (9%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dictionaries for model to losses, accuracies.\n",
    "loss_dict = {}\n",
    "accuracy_dict = {}\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    #Create callback for appending losses.\n",
    "    loss_dict[name] = []\n",
    "    appendLoss = createAppendLossTo(loss_dict[name])\n",
    "    #Create callback for appending accuracies.\n",
    "    accuracy_dict[name] = []\n",
    "    appendAccuracy = createAppendAccuracyTo(accuracy_dict[name])\n",
    "\n",
    "    # put the model on GPU\n",
    "    model.cuda() \n",
    "    # add optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr = args['lr'])\n",
    "\n",
    "    #loop through epoches.\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "        #name the model\n",
    "        print(\"======{}======\".format(name))\n",
    "        print()\n",
    "\n",
    "        train(epoch, callbacks=(printTrainReport, appendLoss))\n",
    "        test(epoch, callbacks=(printTestReport, appendAccuracy))\n",
    "\n",
    "    print()\n",
    "\n",
    "#create data frames from maps\n",
    "losses = pd.DataFrame(loss_dict)\n",
    "accuracies = pd.DataFrame(accuracy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c83be15a-8938-41d5-bdf1-3c525ba3fd1b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net</th>\n",
       "      <th>Sigmoid</th>\n",
       "      <th>tanh</th>\n",
       "      <th>ReLU</th>\n",
       "      <th>Leaky ReLU</th>\n",
       "      <th>ELU</th>\n",
       "      <th>softmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.306634</td>\n",
       "      <td>2.311714</td>\n",
       "      <td>2.299449</td>\n",
       "      <td>2.300189</td>\n",
       "      <td>2.307920</td>\n",
       "      <td>2.322921</td>\n",
       "      <td>2.302845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.283218</td>\n",
       "      <td>2.302858</td>\n",
       "      <td>2.306322</td>\n",
       "      <td>2.311559</td>\n",
       "      <td>2.306707</td>\n",
       "      <td>2.315713</td>\n",
       "      <td>2.302926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.243291</td>\n",
       "      <td>2.311781</td>\n",
       "      <td>2.314031</td>\n",
       "      <td>2.311091</td>\n",
       "      <td>2.295137</td>\n",
       "      <td>2.335889</td>\n",
       "      <td>2.302497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.219450</td>\n",
       "      <td>2.305431</td>\n",
       "      <td>2.325886</td>\n",
       "      <td>2.311403</td>\n",
       "      <td>2.309775</td>\n",
       "      <td>2.292083</td>\n",
       "      <td>2.303159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.197454</td>\n",
       "      <td>2.311798</td>\n",
       "      <td>2.338658</td>\n",
       "      <td>2.299278</td>\n",
       "      <td>2.300221</td>\n",
       "      <td>2.313163</td>\n",
       "      <td>2.303544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.165749</td>\n",
       "      <td>2.294499</td>\n",
       "      <td>2.315161</td>\n",
       "      <td>2.299729</td>\n",
       "      <td>2.306120</td>\n",
       "      <td>2.307704</td>\n",
       "      <td>2.302339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.134152</td>\n",
       "      <td>2.305026</td>\n",
       "      <td>2.312526</td>\n",
       "      <td>2.307458</td>\n",
       "      <td>2.305922</td>\n",
       "      <td>2.326939</td>\n",
       "      <td>2.302710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.087051</td>\n",
       "      <td>2.306191</td>\n",
       "      <td>2.313963</td>\n",
       "      <td>2.320302</td>\n",
       "      <td>2.311450</td>\n",
       "      <td>2.319136</td>\n",
       "      <td>2.302558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.228055</td>\n",
       "      <td>2.304497</td>\n",
       "      <td>2.321942</td>\n",
       "      <td>2.302535</td>\n",
       "      <td>2.306501</td>\n",
       "      <td>2.308650</td>\n",
       "      <td>2.303172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.122716</td>\n",
       "      <td>2.296151</td>\n",
       "      <td>2.323035</td>\n",
       "      <td>2.304860</td>\n",
       "      <td>2.308195</td>\n",
       "      <td>2.309351</td>\n",
       "      <td>2.302449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c83be15a-8938-41d5-bdf1-3c525ba3fd1b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c83be15a-8938-41d5-bdf1-3c525ba3fd1b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c83be15a-8938-41d5-bdf1-3c525ba3fd1b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "          Net   Sigmoid      tanh      ReLU  Leaky ReLU       ELU   softmax\n",
       "0    2.306634  2.311714  2.299449  2.300189    2.307920  2.322921  2.302845\n",
       "1    2.283218  2.302858  2.306322  2.311559    2.306707  2.315713  2.302926\n",
       "2    2.243291  2.311781  2.314031  2.311091    2.295137  2.335889  2.302497\n",
       "3    2.219450  2.305431  2.325886  2.311403    2.309775  2.292083  2.303159\n",
       "4    2.197454  2.311798  2.338658  2.299278    2.300221  2.313163  2.303544\n",
       "..        ...       ...       ...       ...         ...       ...       ...\n",
       "595  0.165749  2.294499  2.315161  2.299729    2.306120  2.307704  2.302339\n",
       "596  0.134152  2.305026  2.312526  2.307458    2.305922  2.326939  2.302710\n",
       "597  0.087051  2.306191  2.313963  2.320302    2.311450  2.319136  2.302558\n",
       "598  0.228055  2.304497  2.321942  2.302535    2.306501  2.308650  2.303172\n",
       "599  0.122716  2.296151  2.323035  2.304860    2.308195  2.309351  2.302449\n",
       "\n",
       "[600 rows x 7 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8d1d5083-6584-41ee-9297-78859b27f3a6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net</th>\n",
       "      <th>Sigmoid</th>\n",
       "      <th>tanh</th>\n",
       "      <th>ReLU</th>\n",
       "      <th>Leaky ReLU</th>\n",
       "      <th>ELU</th>\n",
       "      <th>softmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(88.7500)</td>\n",
       "      <td>tensor(9.8000)</td>\n",
       "      <td>tensor(11.6700)</td>\n",
       "      <td>tensor(11.0900)</td>\n",
       "      <td>tensor(10.2400)</td>\n",
       "      <td>tensor(8.6400)</td>\n",
       "      <td>tensor(8.9200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(90.9700)</td>\n",
       "      <td>tensor(9.8000)</td>\n",
       "      <td>tensor(11.6700)</td>\n",
       "      <td>tensor(11.0900)</td>\n",
       "      <td>tensor(10.2400)</td>\n",
       "      <td>tensor(8.6400)</td>\n",
       "      <td>tensor(8.9200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(92.4200)</td>\n",
       "      <td>tensor(9.8000)</td>\n",
       "      <td>tensor(11.6700)</td>\n",
       "      <td>tensor(11.0900)</td>\n",
       "      <td>tensor(10.2400)</td>\n",
       "      <td>tensor(8.6400)</td>\n",
       "      <td>tensor(8.9200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(92.9100)</td>\n",
       "      <td>tensor(9.8000)</td>\n",
       "      <td>tensor(11.6700)</td>\n",
       "      <td>tensor(11.0900)</td>\n",
       "      <td>tensor(10.2400)</td>\n",
       "      <td>tensor(8.6400)</td>\n",
       "      <td>tensor(8.9200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(93.6200)</td>\n",
       "      <td>tensor(9.8000)</td>\n",
       "      <td>tensor(11.6700)</td>\n",
       "      <td>tensor(11.0900)</td>\n",
       "      <td>tensor(10.2400)</td>\n",
       "      <td>tensor(8.6400)</td>\n",
       "      <td>tensor(8.9200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensor(94.1100)</td>\n",
       "      <td>tensor(9.8000)</td>\n",
       "      <td>tensor(11.6700)</td>\n",
       "      <td>tensor(11.0900)</td>\n",
       "      <td>tensor(10.2400)</td>\n",
       "      <td>tensor(8.6400)</td>\n",
       "      <td>tensor(8.9200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tensor(94.4300)</td>\n",
       "      <td>tensor(9.8000)</td>\n",
       "      <td>tensor(11.6700)</td>\n",
       "      <td>tensor(11.0900)</td>\n",
       "      <td>tensor(10.2400)</td>\n",
       "      <td>tensor(8.6400)</td>\n",
       "      <td>tensor(8.9200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tensor(94.8400)</td>\n",
       "      <td>tensor(9.8000)</td>\n",
       "      <td>tensor(11.6700)</td>\n",
       "      <td>tensor(11.0900)</td>\n",
       "      <td>tensor(10.2400)</td>\n",
       "      <td>tensor(8.6400)</td>\n",
       "      <td>tensor(8.9200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tensor(95.1500)</td>\n",
       "      <td>tensor(9.8000)</td>\n",
       "      <td>tensor(11.6700)</td>\n",
       "      <td>tensor(11.0900)</td>\n",
       "      <td>tensor(10.2400)</td>\n",
       "      <td>tensor(8.6400)</td>\n",
       "      <td>tensor(8.9200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensor(95.4800)</td>\n",
       "      <td>tensor(9.8000)</td>\n",
       "      <td>tensor(11.6700)</td>\n",
       "      <td>tensor(11.0900)</td>\n",
       "      <td>tensor(10.2400)</td>\n",
       "      <td>tensor(8.6400)</td>\n",
       "      <td>tensor(8.9200)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d1d5083-6584-41ee-9297-78859b27f3a6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8d1d5083-6584-41ee-9297-78859b27f3a6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8d1d5083-6584-41ee-9297-78859b27f3a6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               Net         Sigmoid             tanh             ReLU  \\\n",
       "0  tensor(88.7500)  tensor(9.8000)  tensor(11.6700)  tensor(11.0900)   \n",
       "1  tensor(90.9700)  tensor(9.8000)  tensor(11.6700)  tensor(11.0900)   \n",
       "2  tensor(92.4200)  tensor(9.8000)  tensor(11.6700)  tensor(11.0900)   \n",
       "3  tensor(92.9100)  tensor(9.8000)  tensor(11.6700)  tensor(11.0900)   \n",
       "4  tensor(93.6200)  tensor(9.8000)  tensor(11.6700)  tensor(11.0900)   \n",
       "5  tensor(94.1100)  tensor(9.8000)  tensor(11.6700)  tensor(11.0900)   \n",
       "6  tensor(94.4300)  tensor(9.8000)  tensor(11.6700)  tensor(11.0900)   \n",
       "7  tensor(94.8400)  tensor(9.8000)  tensor(11.6700)  tensor(11.0900)   \n",
       "8  tensor(95.1500)  tensor(9.8000)  tensor(11.6700)  tensor(11.0900)   \n",
       "9  tensor(95.4800)  tensor(9.8000)  tensor(11.6700)  tensor(11.0900)   \n",
       "\n",
       "        Leaky ReLU             ELU         softmax  \n",
       "0  tensor(10.2400)  tensor(8.6400)  tensor(8.9200)  \n",
       "1  tensor(10.2400)  tensor(8.6400)  tensor(8.9200)  \n",
       "2  tensor(10.2400)  tensor(8.6400)  tensor(8.9200)  \n",
       "3  tensor(10.2400)  tensor(8.6400)  tensor(8.9200)  \n",
       "4  tensor(10.2400)  tensor(8.6400)  tensor(8.9200)  \n",
       "5  tensor(10.2400)  tensor(8.6400)  tensor(8.9200)  \n",
       "6  tensor(10.2400)  tensor(8.6400)  tensor(8.9200)  \n",
       "7  tensor(10.2400)  tensor(8.6400)  tensor(8.9200)  \n",
       "8  tensor(10.2400)  tensor(8.6400)  tensor(8.9200)  \n",
       "9  tensor(10.2400)  tensor(8.6400)  tensor(8.9200)  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCUF04MYbYcs"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we will plot semilogy with dB on x, like a BER plot\n",
    "N_ITERATIONS = losses.shape[0]\n",
    "iterations_lin = torch.Tensor(range(N_ITERATIONS))\n",
    "iterations_db = 20*torch.log(iterations_lin)\n",
    "# plot the loss\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.semilogy(iterations_db, losses)\n",
    "ax.set_title('loss rate vs iteration')\n",
    "ax.set_xlabel('iteration [db]')\n",
    "ax.set_ylabel('loss rate')\n",
    "ax.legend(model_names)\n",
    "ax.grid(color='silver', which='minor', axis='y', linestyle='solid')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we will plot with dB on x.\n",
    "# this linearizes for the Net model\n",
    "N_EPOCHS = accuracies.shape[0]\n",
    "epoch_lin = torch.Tensor(range(1, (N_EPOCHS + 1)))\n",
    "epoch_db = 20*torch.log(epoch_lin)\n",
    "# plot the accuracy\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(epoch_db, accuracies)\n",
    "ax.set_title('accuracy vs epoch')\n",
    "ax.set_xlabel('epoch [dB]')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.legend(model_names)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-ThwUJxbYcs"
   },
   "source": [
    "### 2. Please use different layers in the model, e.g., 1 layer, 5 layers, 10 layers,  and then plot the training loss and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "models2 = [Net()]\n",
    "model2_names = ['3 layers']\n",
    "print(models2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2fTAFyEbYcs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer1Net(\n",
      "  (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# build an mlp for 1 layer\n",
    "class Layer1Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Layer1Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(28*28, 10)   # linear layer (784 -> 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = x.view(-1,28*28) #input layer\n",
    "        h1 = self.fc1(h0) # output layer\n",
    "\n",
    "        return h1\n",
    "\n",
    "models2.append(Layer1Net())\n",
    "model2_names.append('1 layer')\n",
    "print(models2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======3 layers======\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.299619\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.313098\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.322230\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.315152\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.314519\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.308892\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.319890\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.310707\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.315900\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.316252\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.307339\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 2.309108\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.318660\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 2.312649\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.302337\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.301393\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.311364\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 2.291573\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.305362\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 2.313267\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.308492\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 2.301528\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 2.311426\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 2.316232\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.320110\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.312706\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 2.324941\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 2.300820\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 2.319640\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 2.305924\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.309852\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 2.311116\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.306856\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 2.293870\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 2.321298\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.307856\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 2.309452\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 2.305153\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 2.307615\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 2.323539\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.305102\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 2.318194\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 2.304137\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 2.317119\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 2.312031\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.335512\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 2.326804\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 2.313476\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.314297\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 2.299472\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.301419\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 2.296640\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 2.321236\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 2.309159\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 2.301137\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.316973\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 2.288634\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 2.316411\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 2.309488\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 2.308775\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 402/10000 (4%)\n",
      "\n",
      "======3 layers======\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.317869\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 2.321690\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 2.321648\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 2.326289\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 2.311915\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 2.313171\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 2.298990\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 2.309353\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 2.315950\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 2.298665\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.315729\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 2.316854\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 2.311952\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 2.320072\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 2.305842\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 2.325000\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.307837\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 2.311634\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 2.292724\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 2.300066\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.313406\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 2.299395\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 2.300221\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 2.317144\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 2.318649\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 2.307220\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 2.318703\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 2.313274\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 2.320435\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 2.310629\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.330191\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 2.306752\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.311859\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 2.314608\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 2.296968\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 2.329621\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 2.316130\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 2.320046\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 2.302664\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 2.310116\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.293267\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 2.317698\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 2.319410\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 2.297487\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 2.325449\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 2.309160\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 2.307432\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 2.307821\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 2.310929\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 2.319392\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 2.302182\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 2.320554\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 2.305356\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 2.316812\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 2.314658\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 2.308063\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 2.311652\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 2.326511\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 2.303112\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 2.321107\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 402/10000 (4%)\n",
      "\n",
      "======3 layers======\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.317895\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 2.314379\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 2.316707\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 2.304101\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 2.310317\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 2.301244\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 2.315513\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 2.308038\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 2.312931\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 2.308791\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 2.298813\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 2.332996\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 2.312718\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 2.303747\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 2.323141\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 2.299601\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 2.314623\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 2.319919\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 2.302310\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 2.330689\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 2.297094\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 2.330740\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 2.311048\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 2.308153\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 2.328144\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 2.321520\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 2.321901\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 2.302814\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 2.322868\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 2.307262\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 2.320620\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 2.309995\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.304174\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 2.313258\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 2.309645\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 2.321442\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 2.313305\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 2.328237\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 2.315275\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 2.320736\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 2.314835\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 2.315420\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 2.315197\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 2.314302\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 2.341304\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 2.298783\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 2.303463\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 2.330437\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 2.314909\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 2.312072\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 2.303419\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 2.294424\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 2.315138\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 2.303157\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 2.303014\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 2.310930\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 2.306436\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 2.308728\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 2.315324\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 2.310250\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 402/10000 (4%)\n",
      "\n",
      "======3 layers======\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.318083\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 2.315324\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 2.320822\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 2.305276\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 2.318959\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 2.313715\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 2.301576\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 2.324681\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 2.299844\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 2.308440\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 2.310395\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 2.304162\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 2.311691\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 2.302687\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 2.325438\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 2.305016\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 2.306451\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 2.313238\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 2.310874\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 2.313132\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 2.316214\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 2.311326\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 2.314685\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 2.309256\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 2.327096\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 2.329062\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 2.326797\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 2.312557\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 2.299791\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 2.315051\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 2.295963\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 2.295716\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.311201\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 2.308768\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 2.315781\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 2.285315\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 2.318732\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 2.320952\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 2.293831\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 2.312096\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 2.299748\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 2.303935\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 2.309954\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 2.314819\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 2.312684\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 2.311034\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 2.319062\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 2.308137\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 2.311172\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 2.309350\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 2.292033\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 2.323061\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 2.315922\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 2.326687\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 2.321723\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 2.313740\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 2.309408\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 2.314113\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 2.334425\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 2.311597\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 402/10000 (4%)\n",
      "\n",
      "======3 layers======\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.307705\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 2.310979\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 2.326652\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 2.308137\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 2.317939\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 2.300854\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 2.324626\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 2.297252\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 2.292592\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 2.309349\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 2.305392\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 2.303990\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 2.313097\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 2.319266\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 2.299074\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 2.312304\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 2.321011\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 2.320441\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 2.330055\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 2.298932\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 2.310793\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 2.301912\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 2.304718\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 2.313008\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 2.305529\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 2.312932\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 2.320939\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 2.320647\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 2.320792\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 2.323364\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 2.309361\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 2.322078\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.311426\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 2.319239\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 2.311327\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 2.332934\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 2.312124\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 2.312410\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 2.314883\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 2.317208\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 2.311621\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 2.306570\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 2.310318\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 2.313084\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 2.309210\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 2.311966\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 2.305319\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 2.303774\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 2.323752\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 2.304491\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 2.305847\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 2.316677\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 2.303717\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 2.313836\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 2.321479\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 2.313805\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 2.313770\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 2.321866\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 2.317731\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 2.316289\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 402/10000 (4%)\n",
      "\n",
      "======3 layers======\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.322917\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 2.323840\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 2.300542\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 2.326381\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 2.310648\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 2.313852\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 2.311787\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 2.290908\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 2.309666\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 2.294296\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 2.311275\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 2.309455\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 2.309051\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 2.301443\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 2.294077\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 2.304797\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 2.314249\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 2.325212\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 2.297361\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 2.322792\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 2.319985\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 2.307255\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 2.306919\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 2.313891\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 2.330870\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 2.307339\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 2.309619\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 2.320147\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 2.317185\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 2.311796\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 2.304769\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 2.322428\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.301882\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 2.308064\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 2.326973\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 2.306974\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 2.326506\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 2.313164\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 2.323368\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 2.318842\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 2.298887\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 2.317659\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 2.317216\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 2.322325\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 2.318679\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 2.305603\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 2.311708\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 2.292024\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 2.300076\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 2.302413\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 2.316169\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 2.314384\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 2.318923\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 2.319599\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 2.307381\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 2.311080\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 2.309548\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 2.325712\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 2.308819\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 2.307887\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 402/10000 (4%)\n",
      "\n",
      "======3 layers======\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.327982\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 2.311077\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 2.314461\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 2.316009\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 2.305863\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 2.327135\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 2.311591\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 2.303091\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 2.314076\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 2.312371\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 2.292413\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 2.313626\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 2.296894\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 2.309221\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 2.326812\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 2.325913\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 2.315821\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 2.312905\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 2.312535\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 2.298801\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 2.324611\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 2.320664\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 2.293785\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 2.310854\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 2.317376\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 2.312708\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 2.303697\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 2.311601\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 2.301559\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 2.304826\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 2.311162\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 2.315859\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.303321\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 2.304252\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 2.312670\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 2.316744\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 2.292014\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 2.293151\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 2.312360\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 2.309302\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 2.297247\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 2.298060\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 2.316670\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 2.303867\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 2.313074\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 2.313750\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 2.330332\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 2.311689\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 2.299925\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 2.310758\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 2.306053\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 2.313534\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 2.309827\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 2.327709\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 2.309078\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 2.316298\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 2.316355\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 2.308985\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 2.313010\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 2.304761\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 402/10000 (4%)\n",
      "\n",
      "======3 layers======\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.322480\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 2.315616\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 2.304560\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 2.319780\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 2.318581\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 2.311923\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 2.323081\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 2.321603\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 2.314794\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 2.314376\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 2.315489\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 2.310742\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 2.332053\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 2.306104\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 2.312862\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 2.318702\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 2.307214\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 2.297034\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 2.309517\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 2.319571\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 2.313067\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 2.318967\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 2.313410\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 2.302679\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 2.314612\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 2.315886\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 2.313339\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 2.328905\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 2.318061\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 2.309049\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 2.315573\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 2.308829\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.325995\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 2.306981\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 2.314866\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 2.313255\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 2.320158\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 2.302223\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 2.308654\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 2.306329\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 2.309345\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 2.318586\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 2.300951\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 2.318220\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 2.318211\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 2.327373\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 2.300979\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 2.319338\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 2.334394\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 2.328101\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 2.308723\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 2.312302\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 2.310754\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 2.311332\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 2.304653\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 2.321603\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 2.317712\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 2.313638\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 2.321051\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 2.324729\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 402/10000 (4%)\n",
      "\n",
      "======3 layers======\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.301983\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 2.286358\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 2.332506\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 2.319726\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 2.323712\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 2.319132\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 2.296084\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 2.287812\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 2.311905\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 2.313448\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 2.308670\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 2.311604\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 2.319427\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 2.299534\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 2.320161\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 2.310733\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 2.313093\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 2.327208\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 2.299601\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 2.299303\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 2.307490\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 2.314192\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 2.325293\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 2.319065\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 2.321966\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 2.319304\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 2.315248\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 2.296436\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 2.295578\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 2.322358\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 2.296621\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 2.305957\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.313555\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 2.319963\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 2.314202\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 2.323034\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 2.324607\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 2.308888\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 2.310268\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 2.326801\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 2.325491\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 2.300904\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 2.322152\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 2.312566\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 2.315656\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 2.306932\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 2.311672\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 2.301539\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 2.307181\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 2.314175\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 2.305427\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 2.330591\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 2.318513\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 2.295386\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 2.317820\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 2.286538\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 2.319445\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 2.321007\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 2.319743\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 2.318820\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 402/10000 (4%)\n",
      "\n",
      "======3 layers======\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.312431\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 2.306810\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 2.303690\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 2.321117\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 2.319894\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 2.311540\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 2.309348\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 2.319924\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 2.331186\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 2.328960\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 2.312039\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 2.307249\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 2.290819\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 2.328862\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 2.308574\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 2.300511\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 2.317023\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 2.305887\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 2.315350\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 2.315950\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 2.323514\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 2.314495\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 2.309842\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 2.316092\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 2.291880\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 2.322909\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 2.334889\n",
      "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 2.316908\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 2.289986\n",
      "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 2.322132\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 2.310414\n",
      "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 2.303483\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.315521\n",
      "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 2.305389\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 2.313076\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 2.315522\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 2.289800\n",
      "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 2.330320\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 2.296085\n",
      "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 2.279969\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 2.340045\n",
      "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 2.300181\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 2.305256\n",
      "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 2.312178\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 2.295829\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 2.308209\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 2.333169\n",
      "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 2.326988\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 2.325175\n",
      "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 2.338844\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 2.319694\n",
      "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 2.300327\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 2.307504\n",
      "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 2.312247\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 2.307243\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 2.288244\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 2.315721\n",
      "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 2.317842\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 2.311255\n",
      "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 2.330432\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 402/10000 (4%)\n",
      "\n",
      "\n",
      "======1 layer======\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.377189\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.333858\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.368948\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.303245\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.341303\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.299983\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.351396\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.396153\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.352120\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.307203\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.429996\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 2.348195\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.340197\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 2.378097\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.374938\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.456825\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.373829\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 2.357437\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.390311\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 2.386624\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.360741\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 2.377196\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 2.322302\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 2.341358\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.404155\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.403605\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 2.338386\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 2.325905\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 2.277510\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 2.354165\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.316352\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 2.248564\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.439131\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 2.338702\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 2.435714\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.382870\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 2.433356\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 2.366382\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 2.361163\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 2.354473\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.355847\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 2.357960\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 2.312342\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 2.315404\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 2.417383\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.212553\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 2.432892\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 2.358606\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.344416\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 2.388789\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.344299\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 2.397902\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 2.336183\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 2.420157\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 2.435209\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.388873\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 2.333561\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 2.450409\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 2.352073\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 2.382293\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1114/10000 (11%)\n",
      "\n",
      "======1 layer======\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.358448\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 2.374179\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 2.275073\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 2.411968\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 2.284635\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 2.360321\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 2.295862\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 2.278628\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 2.392126\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 2.361999\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.399687\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 2.393857\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 2.386452\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 2.449542\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 2.383513\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 2.343033\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.281623\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 2.364406\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 2.420613\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 2.392378\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.363197\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 2.362484\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 2.444543\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 2.344413\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 2.263526\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 2.282824\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 2.411583\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 2.355351\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 2.360034\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 2.339844\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.358675\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 2.311238\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.408751\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 2.446625\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 2.407855\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 2.356110\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 2.396113\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 2.280602\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 2.303987\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 2.387667\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.382814\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 2.356641\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 2.349769\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 2.404868\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 2.340768\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 2.401428\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 2.359693\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 2.378784\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 2.413643\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 2.285163\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 2.312404\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 2.333864\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 2.443684\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 2.311028\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 2.401031\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 2.375321\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 2.328876\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 2.456380\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 2.332926\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 2.414325\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1114/10000 (11%)\n",
      "\n",
      "======1 layer======\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.459583\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 2.362841\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 2.363506\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 2.324325\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 2.411397\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 2.397107\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 2.332909\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 2.373850\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 2.418906\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 2.417225\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 2.230009\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 2.378812\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 2.387262\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 2.292737\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 2.289026\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 2.439269\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 2.294418\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 2.343571\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 2.358954\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 2.348249\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 2.417946\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 2.456352\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 2.381296\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 2.400868\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 2.310919\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 2.378142\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 2.361852\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 2.431345\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 2.396584\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 2.394055\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 2.315480\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 2.381216\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.300930\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 2.292245\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 2.312280\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 2.412476\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 2.395818\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 2.352807\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 2.383114\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 2.441330\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 2.394068\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 2.325367\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 2.403510\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 2.366342\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 2.389260\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 2.406919\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 2.272895\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 2.367734\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 2.312473\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 2.350019\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 2.394794\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 2.350876\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 2.360493\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 2.328734\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 2.321689\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 2.328592\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 2.394110\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 2.395792\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 2.301724\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 2.383519\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1114/10000 (11%)\n",
      "\n",
      "======1 layer======\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.425496\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 2.329274\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 2.448687\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 2.323686\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 2.455371\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 2.396176\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 2.350097\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 2.389619\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 2.488123\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 2.269858\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 2.388131\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 2.426705\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 2.400300\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 2.339186\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 2.394406\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 2.359409\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 2.389513\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 2.392808\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 2.339166\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 2.293090\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 2.354365\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 2.397610\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 2.419595\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 2.276845\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 2.397256\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 2.369236\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 2.330734\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 2.407817\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 2.243757\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 2.326768\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 2.387921\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 2.344213\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.294397\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 2.252264\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 2.369379\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 2.427584\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 2.324966\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 2.426967\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 2.329678\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 2.408611\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 2.363296\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 2.348755\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 2.421395\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 2.382677\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 2.289967\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 2.330443\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 2.358326\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 2.362949\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 2.317557\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 2.346788\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 2.388711\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 2.329821\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 2.329465\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 2.424300\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 2.303702\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 2.392722\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 2.366191\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 2.349783\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 2.382573\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 2.422813\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1114/10000 (11%)\n",
      "\n",
      "======1 layer======\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.380471\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 2.343322\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 2.318870\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 2.304932\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 2.369747\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 2.416073\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 2.405542\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 2.342152\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 2.496344\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 2.309796\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 2.406130\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 2.366947\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 2.386179\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 2.346044\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 2.388073\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 2.359286\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 2.312833\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 2.399719\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 2.357606\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 2.353708\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 2.402383\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 2.365456\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 2.292197\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 2.308722\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 2.361157\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 2.385326\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 2.243858\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 2.325937\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 2.372826\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 2.311952\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 2.468634\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 2.287927\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.375599\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 2.405796\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 2.352602\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 2.372065\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 2.314442\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 2.344609\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 2.431966\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 2.378038\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 2.371892\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 2.432987\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 2.369453\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 2.360671\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 2.375349\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 2.328496\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 2.356654\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 2.358463\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 2.422910\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 2.387637\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 2.284906\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 2.413726\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 2.439867\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 2.387358\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 2.337778\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 2.317823\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 2.417534\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 2.428754\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 2.384533\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 2.361401\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1114/10000 (11%)\n",
      "\n",
      "======1 layer======\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.418238\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 2.367055\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 2.334549\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 2.325716\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 2.344041\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 2.354068\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 2.353646\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 2.342843\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 2.346343\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 2.396307\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 2.320621\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 2.352396\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 2.330585\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 2.374690\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 2.373433\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 2.332111\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 2.337847\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 2.265866\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 2.302388\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 2.415386\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 2.370852\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 2.294021\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 2.390955\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 2.340144\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 2.366236\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 2.425354\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 2.311222\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 2.395199\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 2.315470\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 2.358623\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 2.286306\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 2.367781\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.441183\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 2.470680\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 2.353425\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 2.382638\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 2.388069\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 2.393890\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 2.406898\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 2.346639\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 2.365967\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 2.334548\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 2.451201\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 2.370770\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 2.325242\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 2.321325\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 2.349706\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 2.474340\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 2.458532\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 2.308993\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 2.376704\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 2.334090\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 2.433283\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 2.390231\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 2.381391\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 2.295953\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 2.420414\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 2.316620\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 2.371297\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 2.395492\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1114/10000 (11%)\n",
      "\n",
      "======1 layer======\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.342807\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 2.256052\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 2.407166\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 2.377743\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 2.381422\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 2.393659\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 2.395612\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 2.382432\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 2.366834\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 2.271671\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 2.359377\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 2.354041\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 2.361855\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 2.345801\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 2.457002\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 2.363414\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 2.428448\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 2.361363\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 2.326116\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 2.375893\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 2.387886\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 2.464922\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 2.293595\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 2.380902\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 2.333582\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 2.393028\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 2.367126\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 2.411402\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 2.301773\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 2.400754\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 2.346981\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 2.408636\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.431389\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 2.351408\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 2.400852\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 2.364734\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 2.363003\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 2.264767\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 2.426107\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 2.326343\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 2.379430\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 2.340732\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 2.310198\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 2.321007\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 2.338193\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 2.356757\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 2.369900\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 2.357342\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 2.347434\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 2.386779\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 2.483430\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 2.278394\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 2.385888\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 2.398858\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 2.346499\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 2.335918\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 2.358942\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 2.333938\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 2.328386\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 2.338396\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1114/10000 (11%)\n",
      "\n",
      "======1 layer======\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.229637\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 2.347424\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 2.359468\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 2.314430\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 2.372011\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 2.319531\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 2.385108\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 2.395314\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 2.370322\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 2.381870\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 2.366311\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 2.272489\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 2.451395\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 2.396870\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 2.397429\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 2.350463\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 2.411259\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 2.349366\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 2.382400\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 2.369887\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 2.341483\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 2.361578\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 2.356262\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 2.358364\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 2.416579\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 2.245485\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 2.330903\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 2.299447\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 2.384745\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 2.385518\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 2.456523\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 2.397021\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.288820\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 2.341708\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 2.373878\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 2.386707\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 2.320974\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 2.403490\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 2.269321\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 2.436156\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 2.345809\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 2.404092\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 2.340434\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 2.344295\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 2.307621\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 2.395001\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 2.314067\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 2.375293\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 2.346777\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 2.380510\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 2.471980\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 2.336723\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 2.415070\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 2.373390\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 2.349635\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 2.449755\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 2.394428\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 2.381001\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 2.324018\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 2.257224\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1114/10000 (11%)\n",
      "\n",
      "======1 layer======\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.407577\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 2.349426\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 2.413092\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 2.305608\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 2.454176\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 2.301885\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 2.413656\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 2.314601\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 2.407850\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 2.359842\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 2.404568\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 2.305878\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 2.338704\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 2.348000\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 2.342607\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 2.350450\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 2.352509\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 2.356428\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 2.315376\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 2.381857\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 2.344459\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 2.404293\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 2.367324\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 2.341002\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 2.251470\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 2.265906\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 2.396710\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 2.296182\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 2.352235\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 2.362813\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 2.338490\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 2.459373\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.315620\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 2.383450\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 2.343508\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 2.376587\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 2.404466\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 2.452299\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 2.488047\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 2.474691\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 2.421524\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 2.282017\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 2.411835\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 2.325316\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 2.369798\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 2.368747\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 2.391574\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 2.309289\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 2.310580\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 2.317155\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 2.364869\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 2.405542\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 2.361391\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 2.427667\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 2.432725\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 2.275042\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 2.308780\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 2.403638\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 2.384724\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 2.316072\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1114/10000 (11%)\n",
      "\n",
      "======1 layer======\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.438886\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 2.356641\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 2.424799\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 2.353768\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 2.395603\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 2.384830\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 2.316414\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 2.345919\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 2.365654\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 2.295737\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 2.325570\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 2.417853\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 2.378333\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 2.327826\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 2.427392\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 2.316314\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 2.323651\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 2.341578\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 2.316335\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 2.304547\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 2.394182\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 2.330869\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 2.397253\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 2.414995\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 2.440878\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 2.429355\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 2.378166\n",
      "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 2.426116\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 2.294954\n",
      "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 2.390274\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 2.391161\n",
      "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 2.336876\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.426211\n",
      "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 2.421145\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 2.292572\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 2.363277\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 2.383554\n",
      "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 2.440146\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 2.363188\n",
      "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 2.284601\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 2.339071\n",
      "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 2.418809\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 2.375623\n",
      "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 2.434850\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 2.335942\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 2.385552\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 2.357040\n",
      "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 2.425869\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 2.378832\n",
      "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 2.290107\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 2.362848\n",
      "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 2.321336\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 2.362270\n",
      "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 2.415445\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 2.402026\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 2.431572\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 2.375218\n",
      "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 2.367399\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 2.402061\n",
      "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 2.350428\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1114/10000 (11%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dictionaries for model to losses, accuracies.\n",
    "loss_dict = { }\n",
    "accuracy_dict = { }\n",
    "\n",
    "for model, name in zip(models2, model2_names):\n",
    "    #Create callback for appending losses.\n",
    "    loss_dict[name] = []\n",
    "    appendLoss = createAppendLossTo(loss_dict[name])\n",
    "    #Create callback for appending accuracies.\n",
    "    accuracy_dict[name] = []\n",
    "    appendAccuracy = createAppendAccuracyTo(accuracy_dict[name])\n",
    "\n",
    "    # put the model on GPU\n",
    "    model.cuda() \n",
    "    # add optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr = args['lr'])\n",
    "\n",
    "    #loop through epoches.\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "        #name the model\n",
    "        print(\"======{}======\".format(name))\n",
    "        print()\n",
    "\n",
    "        train(epoch, callbacks=(printTrainReport, appendLoss))\n",
    "        test(epoch, callbacks=(printTestReport, appendAccuracy))\n",
    "\n",
    "    print()\n",
    "\n",
    "#create data frames from maps\n",
    "losses2 = pd.DataFrame(loss_dict)\n",
    "accuracies2 = pd.DataFrame(accuracy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-01b79d5b-83cd-4b46-bd0e-f2c706ec8295\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3 layers</th>\n",
       "      <th>1 layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.299619</td>\n",
       "      <td>2.377189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.313098</td>\n",
       "      <td>2.333858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.322230</td>\n",
       "      <td>2.368948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.315152</td>\n",
       "      <td>2.303245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.314519</td>\n",
       "      <td>2.341303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>2.288244</td>\n",
       "      <td>2.431572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>2.315721</td>\n",
       "      <td>2.375218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>2.317842</td>\n",
       "      <td>2.367399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>2.311255</td>\n",
       "      <td>2.402061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>2.330432</td>\n",
       "      <td>2.350428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01b79d5b-83cd-4b46-bd0e-f2c706ec8295')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-01b79d5b-83cd-4b46-bd0e-f2c706ec8295 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-01b79d5b-83cd-4b46-bd0e-f2c706ec8295');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     3 layers   1 layer\n",
       "0    2.299619  2.377189\n",
       "1    2.313098  2.333858\n",
       "2    2.322230  2.368948\n",
       "3    2.315152  2.303245\n",
       "4    2.314519  2.341303\n",
       "..        ...       ...\n",
       "595  2.288244  2.431572\n",
       "596  2.315721  2.375218\n",
       "597  2.317842  2.367399\n",
       "598  2.311255  2.402061\n",
       "599  2.330432  2.350428\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2e5414fe-9b18-43d2-9d8c-eccc0f72d457\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3 layers</th>\n",
       "      <th>1 layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(4.0200)</td>\n",
       "      <td>tensor(11.1400)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(4.0200)</td>\n",
       "      <td>tensor(11.1400)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(4.0200)</td>\n",
       "      <td>tensor(11.1400)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(4.0200)</td>\n",
       "      <td>tensor(11.1400)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(4.0200)</td>\n",
       "      <td>tensor(11.1400)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensor(4.0200)</td>\n",
       "      <td>tensor(11.1400)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tensor(4.0200)</td>\n",
       "      <td>tensor(11.1400)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tensor(4.0200)</td>\n",
       "      <td>tensor(11.1400)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tensor(4.0200)</td>\n",
       "      <td>tensor(11.1400)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensor(4.0200)</td>\n",
       "      <td>tensor(11.1400)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e5414fe-9b18-43d2-9d8c-eccc0f72d457')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2e5414fe-9b18-43d2-9d8c-eccc0f72d457 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2e5414fe-9b18-43d2-9d8c-eccc0f72d457');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         3 layers          1 layer\n",
       "0  tensor(4.0200)  tensor(11.1400)\n",
       "1  tensor(4.0200)  tensor(11.1400)\n",
       "2  tensor(4.0200)  tensor(11.1400)\n",
       "3  tensor(4.0200)  tensor(11.1400)\n",
       "4  tensor(4.0200)  tensor(11.1400)\n",
       "5  tensor(4.0200)  tensor(11.1400)\n",
       "6  tensor(4.0200)  tensor(11.1400)\n",
       "7  tensor(4.0200)  tensor(11.1400)\n",
       "8  tensor(4.0200)  tensor(11.1400)\n",
       "9  tensor(4.0200)  tensor(11.1400)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCUF04MYbYcs"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we will plot semilogy with dB on x, like a BER plot\n",
    "N_ITERATIONS = losses2.shape[0]\n",
    "iterations_lin = torch.Tensor(range(N_ITERATIONS))\n",
    "iterations_db = 20*torch.log(iterations_lin)\n",
    "# plot the loss\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.semilogy(iterations_db, losses2)\n",
    "ax.set_title('loss rate vs iteration')\n",
    "ax.set_xlabel('iteration [db]')\n",
    "ax.set_ylabel('loss rate')\n",
    "ax.legend(model2_names)\n",
    "ax.grid(color='silver', which='minor', axis='y', linestyle='solid')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we will plot with dB on x.\n",
    "# this linearizes for the Net model\n",
    "epoch_lin = torch.Tensor(range(1, (len(accuracies2) + 1)))\n",
    "epoch_db = 20*torch.log(epoch_lin)\n",
    "# plot the accuracy\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(epoch_db, accuracies2)\n",
    "ax.set_title('accuracy vs epoch')\n",
    "ax.set_xlabel('epoch [dB]')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.legend(model2_names)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
