{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ev7mKEvgbYcZ"
   },
   "source": [
    "# Lab 10: Fully Connected Neural Networks\n",
    "\n",
    "In this assignment, we will learn fully connected neural network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwZwfFQYbYcc"
   },
   "source": [
    "## 1. Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHnoQz3MbYcd"
   },
   "source": [
    "This assignement should be run on Google Colab where you can use free GPU to accelerate the computation. Please refer to our slides to set up GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab][colab badge]][colab]\n",
    "\n",
    "[colab badge]: https://colab.research.google.com/assets/colab-badge.svg\n",
    "[colab]: https://colab.research.google.com/github/lduran2/CIS3715_DataScience_2022/blob/lab10/Lab10/Lab10.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4Rte_TebYce"
   },
   "source": [
    "### 1. Install Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6583,
     "status": "ok",
     "timestamp": 1649559863527,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "outputId": "3ff45b08-cc1c-4281-b8a8-f31d06275642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision   # install pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqu1YdX2bYch"
   },
   "source": [
    "### 2. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1649559865200,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "outputId": "6987f9ee-b3ff-43c5-d4ea-4cd7d2a1ee5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 10 03:04:26 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!/opt/bin/nvidia-smi  #show GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqmII1sAbYcj"
   },
   "source": [
    "### 3. Mount to google drive (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17744,
     "status": "ok",
     "timestamp": 1649274810388,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "id": "HdWuV25Qb-TM",
    "outputId": "09e93d6a-5e99-4510-e3be-eca9853e6566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bAPbFl0bYck"
   },
   "source": [
    "### 4. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nVVA8yeXv9c"
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTnQJNfyhmaE"
   },
   "outputs": [],
   "source": [
    "args={}\n",
    "args['batch_size']=100\n",
    "args['test_batch_size']=100\n",
    "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n",
    "args['lr']=0.01 #Learning rate is how fast it will decend. \n",
    "args['log_interval']=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_rnd(a_seed):\n",
    "    '''\n",
    "    Seeds all relevant RND libaries.\n",
    "    '''\n",
    "    # import and seed numpy if unused\n",
    "    import numpy\n",
    "    numpy.random.seed(a_seed)\n",
    "    # seed Pytorch\n",
    "    torch.manual_seed(a_seed)\n",
    "    # seed the GPU(s)\n",
    "    torch.cuda.manual_seed_all(a_seed)\n",
    "# end seed_rnd(a_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a constant random seed to make experiment repeatable\n",
    "seed_rnd(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1649276322480,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "outputId": "7d252d46-624d-4416-9851-8cdff1ce97da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# build an mlp\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 256)   # linear layer (784 -> 256)\n",
    "        self.fc2 = nn.Linear(256,128)  # linear layer (256 -> 128)\n",
    "        self.fc3 = nn.Linear(128,10)  # linear layer (128 -> 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = x.view(-1,28*28) #input layer\n",
    "        h1 = F.relu(self.fc1(h0)) # hidden layer 1\n",
    "        h2 = F.relu(self.fc2(h1)) # hidden layer 2\n",
    "        h3 = self.fc3(h2) # output layer\n",
    "\n",
    "        return h3\n",
    "\n",
    "model = Net()\n",
    "model.cuda() # put the model on GPU\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0U9yHGoTZi3e"
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = args['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvuVjPqPabRC"
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OipUVawbYcr"
   },
   "source": [
    "## 2. Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have changed the `train` and `test` functions\n",
    "and added some of my own to make it possible to aggregate loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTrainReport(epoch, i_xamp, N_XAMPS, pc_accuracy, r_loss):\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, i_xamp, N_XAMPS, pc_accuracy, r_loss))\n",
    "# end def printTrainReport(epoch, i_xamp, N_XAMPS, pc_accuracy, r_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAppendLossTo(queue):\n",
    "    def appendLossToQueue(epoch, i_xamp, N_XAMPS, pc_accuracy, r_loss):\n",
    "        queue.append(r_loss)\n",
    "    # end def appendLossToQueue(epoch, i_xamp, N_XAMPS, pc_accuracy, r_loss)\n",
    "    return appendLossToQueue\n",
    "# end def createAppendLossTo(queue)(epoch, i_xamp, N_XAMPS, pc_accuracy, r_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YopP0oK5ca2u"
   },
   "outputs": [],
   "source": [
    "def train(epoch, callbacks=[printTrainReport]):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #to do a one-step update on our parameter.\n",
    "        optimizer.step()\n",
    "\n",
    "        #Apply callbacks to the loss periodically. \n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            for callback in callbacks:\n",
    "                callback(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTestReport(epoch, r_test_loss, N_CORRECTS, N_XAMPS, pc_accuracy):\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "        .format(r_test_loss, N_CORRECTS, N_XAMPS, pc_accuracy))\n",
    "# end def printTestReport(epoch, r_test_loss, N_CORRECTS, N_XAMPS, pc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAppendAccuracyTo(queue):\n",
    "    def appendAccuracyToQueue(\n",
    "          epoch, r_test_loss, N_CORRECTS, N_XAMPS, pc_accuracy):\n",
    "        queue.append(pc_accuracy)\n",
    "    # end def appendAccuracyToQueue(\n",
    "    #     epoch, r_test_loss, N_CORRECTS, N_XAMPS, pc_accuracy)\n",
    "    return appendAccuracyToQueue\n",
    "# end def createAppendAccuracyTo(queue)(\n",
    "#     epoch, r_test_loss, N_CORRECTS, N_XAMPS, pc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLn-uP_sct-a"
   },
   "outputs": [],
   "source": [
    "def test(epoch=-1, callbacks=[printTestReport]):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    for callback in callbacks:\n",
    "        callback(\n",
    "            epoch, test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GA50s29XbYcs"
   },
   "source": [
    "### 1. Please use other activation functions, e.g., sigmoid, tanh, and then plot the training loss and testing accuracy. \n",
    "\n",
    "When plotting the training loss, the x-axis is iteration and the y-axis is training loss. When plotting the testing accuracy,  the x-axis is epoch and the y-axis is the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158181,
     "status": "ok",
     "timestamp": 1649276492527,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "outputId": "aaa6553d-5c92-4714-db39-37f12e88f997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307205\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.265357\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.224665\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.230098\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.189282\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.163362\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.121968\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.090820\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.041341\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 1.963370\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.892034\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 1.851569\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.843171\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 1.718554\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.568165\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 1.560181\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.460177\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 1.393085\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.230321\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 1.244536\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.156173\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 1.138016\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.919708\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.849970\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.835899\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.826837\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.722322\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.825099\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.751022\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.769209\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.676518\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.639900\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.739357\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.583162\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.562167\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.657849\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.560251\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.526822\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.638896\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.481967\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.596915\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.681047\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.581280\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.463135\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.553184\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.555955\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.479067\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.523204\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.454037\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.600012\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.466980\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.422386\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.450246\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.424193\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.440435\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.307335\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.524972\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.380341\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.448127\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.440179\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 8879/10000 (89%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.383413\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.451908\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.444330\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.385382\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.327716\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.441603\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.337230\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.446643\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.401783\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.336693\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.536712\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.401839\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.305057\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.322054\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.398921\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.357370\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.326384\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.383729\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.272186\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.390242\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.447836\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.341478\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.388536\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.353161\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.342086\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.265260\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.343413\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.198118\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.437403\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.361106\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.248194\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.313770\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.273308\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.333302\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.444734\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.387127\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.462794\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.470779\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.403695\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.227867\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.280609\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.216548\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.266317\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.437185\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.319455\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.396355\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.353069\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.456427\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.340011\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.306393\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.285929\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.366748\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.343209\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.318405\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.330439\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.319498\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.348941\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.262500\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.306078\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.361209\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 9095/10000 (91%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.254429\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.346859\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.300215\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.312957\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.156088\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.315203\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.341175\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.317572\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.312385\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.330022\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.530559\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.221646\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.357675\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.324713\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.199983\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.277110\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.341803\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.278707\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.279108\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.265574\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.346905\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.339671\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.289896\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.192637\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.213236\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.375436\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.462734\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.242336\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.314524\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.407366\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.202049\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.323219\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.231523\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.281360\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.299488\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.361700\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.286314\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.237973\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.278991\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.250037\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.320871\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.375677\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.235637\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.313268\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.250009\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.206338\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.257390\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.246018\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.257955\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.300604\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.261017\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.237784\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.392501\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.253206\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.261482\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.358871\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.519547\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.157640\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.303143\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.182123\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 9237/10000 (92%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.158681\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.190031\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.382939\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.252558\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.276865\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.221599\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.266616\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.350075\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.198126\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.287007\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.236668\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.247152\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.276587\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.231567\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.165653\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.285896\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.312404\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.259943\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.327750\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.348404\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.298943\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.331401\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.339831\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.255960\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.188158\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.297315\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.188243\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.199570\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.279946\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.219646\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.229024\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.292078\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.250079\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.172812\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.149976\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.261852\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.385101\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.167761\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.282622\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.195140\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.282459\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.291734\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.193278\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.261889\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.140289\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.336961\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.309740\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.322119\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.231646\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.260448\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.173356\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.298821\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.234537\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.433110\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.279169\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.278240\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.274073\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.120188\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.394964\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.207737\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 9298/10000 (93%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.300779\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.331432\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.148247\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.290047\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.286970\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.183629\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.192768\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.228193\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.343513\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.115691\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.204813\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.390010\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.359264\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.126214\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.308157\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.261027\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.359347\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.333873\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.323092\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.217612\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.326238\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.328177\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.202732\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.296873\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.239050\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.198790\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.226872\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.195289\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.152807\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.198406\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.241858\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.134092\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.245313\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.159928\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.216758\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.245301\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.296072\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.252536\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.301442\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.280401\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.201284\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.183699\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.240345\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.376345\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.267495\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.437239\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.378072\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.225060\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.260311\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.205806\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.261808\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.148400\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.250996\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.201983\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.205236\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.315065\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.288275\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.144871\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.132610\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.183644\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 9357/10000 (94%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.214059\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 0.281378\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.189737\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 0.281137\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.215646\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.303869\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.250201\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 0.185062\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.140781\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 0.224266\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.317391\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 0.339916\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.226134\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 0.424008\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.211280\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.284944\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.232579\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 0.267720\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.270225\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 0.199884\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.311817\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 0.186391\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.253792\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 0.116106\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.344895\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.245470\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.176190\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 0.272318\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.112626\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 0.217228\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.128835\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 0.283399\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.290562\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 0.267786\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.165317\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.349291\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.167167\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 0.281532\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.161091\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 0.133580\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.130106\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 0.223459\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.253662\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 0.117387\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.301055\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.346329\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.235173\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 0.223225\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.190716\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 0.236786\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.205177\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 0.221464\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.219834\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 0.320261\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.231014\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.197293\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.145152\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 0.188224\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.223416\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 0.209872\n",
      "\n",
      "Test set: Average loss: 0.0020, Accuracy: 9414/10000 (94%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.149402\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 0.196742\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.289352\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 0.244811\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.255978\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.168013\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.166914\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 0.135769\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.225728\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 0.258122\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.119071\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 0.282717\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.172429\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 0.186347\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.138985\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.226085\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.111530\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 0.223599\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.203055\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 0.196469\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.209172\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 0.188824\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.233784\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 0.144293\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.302103\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.073872\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.274851\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 0.160733\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.253017\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 0.262368\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.125315\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 0.099071\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.194050\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 0.119248\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.151628\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.216010\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.263266\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 0.248513\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.246406\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 0.331005\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.305335\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 0.240120\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.076777\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 0.149640\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.104240\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.274059\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.136412\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 0.210383\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.155746\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 0.180165\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.217393\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 0.144284\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.240881\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 0.176545\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.112510\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.163674\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.221222\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 0.189975\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.185219\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 0.217252\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 9449/10000 (94%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.145324\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 0.233045\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.213556\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 0.214221\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.238858\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.192079\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.235394\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 0.200086\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.218072\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 0.219743\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.147067\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 0.072024\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.209941\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 0.274805\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.163059\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.205721\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.308867\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 0.103012\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.095693\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 0.224873\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.218724\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 0.220177\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.174860\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 0.117229\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.137117\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.189147\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.189332\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 0.168144\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.231376\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 0.188796\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.243839\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 0.142418\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.210685\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 0.141884\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.201159\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.167439\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.144800\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 0.111173\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.172652\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 0.274313\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.112963\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 0.183739\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.076322\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 0.189062\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.132613\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.141349\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.224637\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 0.203762\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.117021\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 0.125813\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.143669\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 0.143999\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.273300\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 0.176803\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.178532\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.149943\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.141543\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 0.200144\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.079121\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 0.120871\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 9488/10000 (95%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.180410\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 0.140523\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.133224\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 0.187538\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.245267\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.255853\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.097601\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 0.273273\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.109185\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 0.062004\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.123867\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 0.247213\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.078813\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 0.141484\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.165843\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.065094\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.191470\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 0.193327\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.190783\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 0.180389\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.150090\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 0.096018\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.068573\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 0.158719\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.188869\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.256130\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.121855\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 0.134465\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.245424\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 0.145181\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.245094\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 0.205675\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.057190\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 0.120512\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.166017\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.068598\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.166817\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 0.110966\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.132502\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 0.149902\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.089075\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 0.128322\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.155393\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 0.118242\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.128798\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.139601\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.365700\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 0.120115\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.161780\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 0.182866\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.185085\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 0.150141\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.188476\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 0.129001\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.152562\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.205979\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.145346\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 0.139512\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.122243\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 0.180163\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 9529/10000 (95%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.116699\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 0.267722\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 0.118426\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 0.080985\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 0.132480\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 0.053720\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 0.208348\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 0.236988\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.122841\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 0.130199\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.165283\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 0.070946\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.207154\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 0.260104\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 0.091238\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.129088\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.176386\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 0.097652\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 0.209882\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 0.131270\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.171927\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 0.153760\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 0.156154\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 0.170883\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.189915\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.198786\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 0.124455\n",
      "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 0.146645\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 0.131813\n",
      "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 0.153941\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.095024\n",
      "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 0.119874\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.096836\n",
      "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 0.140457\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 0.138195\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 0.227947\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.120852\n",
      "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 0.207667\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 0.081692\n",
      "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 0.247991\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.038742\n",
      "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 0.110506\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 0.058539\n",
      "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 0.227229\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 0.084377\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 0.059872\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 0.140418\n",
      "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 0.109686\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.230056\n",
      "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 0.272585\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.146837\n",
      "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 0.209682\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 0.424289\n",
      "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 0.123197\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 0.086711\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 0.145367\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.051109\n",
      "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 0.208706\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 0.204404\n",
      "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 0.231093\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 9540/10000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create callback for appending losses.\n",
    "losses = []\n",
    "appendLoss = createAppendLossTo(losses)\n",
    "\n",
    "#Create callback for appending accuracies.\n",
    "accuracies = []\n",
    "appendAccuracy = createAppendAccuracyTo(accuracies)\n",
    "\n",
    "#loop through epoches.\n",
    "for epoch in range(1, args['epochs'] + 1):\n",
    "    train(epoch, callbacks=(printTrainReport, appendLoss))\n",
    "    test(epoch, callbacks=(printTestReport, appendAccuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCUF04MYbYcs"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(losses)\n",
    "ax.set_title('loss rate vs iteration')\n",
    "ax.set_xlabel('iteration')\n",
    "ax.set_ylabel('loss rate')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "epoch_nos = range(1, (len(accuracies) + 1))\n",
    "ax.plot(epoch_nos, accuracies)\n",
    "ax.set_title('accuracy vs epoch')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('accuracy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-ThwUJxbYcs"
   },
   "source": [
    "### 2. Please use different layers in the model, e.g., 1 layer, 5 layers, 10 layers,  and then plot the training loss and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2fTAFyEbYcs"
   },
   "outputs": [],
   "source": [
    "# your code"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
