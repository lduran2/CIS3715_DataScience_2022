{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9: Document Analysis\n",
    "\n",
    "In this assignment, we will learn how to do document classification and clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Example\n",
    "\n",
    "In this example, we use [20newsgroups](https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset) dataset. Each sample is a document and there are totally 20 classes. \n",
    "\n",
    "### 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data target labels: [7 4 4 ... 3 1 8]\n",
      "Train data target names: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "#training samples: 11314\n",
      "#testing samples: 7532\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "data_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "print(\"Train data target labels: {}\".format(data_train.target))\n",
    "print(\"Train data target names: {}\".format(data_train.target_names))\n",
    "\n",
    "print('#training samples: {}'.format(len(data_train.data)))\n",
    "print('#testing samples: {}'.format(len(data_test.data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Represent documents with TF-IDF represention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<dl>\n",
    "    <div>\n",
    "        <dt><abbr described-by='tf-idf-title'>TF-IDF</abbr></dt>\n",
    "        <dd role='tooltip' id='tf-idf-title'>Term Frequency-Inverse Document Frequency</dd>\n",
    "        <dd>Reflect how important a word is to a document in a collection</dd>\n",
    "        <dd>\n",
    "            $$\n",
    "                \\operatorname{TF\\_IDF}\\left(t, d, \\mathcal{D}\\right)\n",
    "                := \\operatorname{TF}\\left(t, d\\right)%\n",
    "                \\times\\operatorname{IDF}\\left(t, \\mathcal{D}\\right),\n",
    "            $$\n",
    "            where Term frequency\n",
    "            $$\n",
    "                \\operatorname{TF}\\left(t, d\\right)\n",
    "                := \\frac{\\#\\left(t\\text{ in document }d\\right)}\n",
    "                {\\#\\left(\\mathbf{words}\\text{ in document }d\\right)}\n",
    "            $$\n",
    "            measures the frequency of a word in a document,\n",
    "            and Inverse Document Frequency\n",
    "            $$\n",
    "                \\operatorname{IDF}\\left(t, \\mathcal{D}\\right)\n",
    "                := \\log\\left(\n",
    "                    \\mathbb{P}^{-1}\\!\\left\\{\\mathcal{D}\\text{ contains }t\\right\\}\n",
    "                \\right)\n",
    "            $$\n",
    "            measures the rareness of a word <strong>in all documents</strong>.\n",
    "        </dd>\n",
    "    </div>\n",
    "</dl>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 101631) (7532, 101631)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#TF-IDF representation for each document\n",
    "vectorizer = TfidfVectorizer()\n",
    "data_train_vectors = vectorizer.fit_transform(data_train.data)\n",
    "data_test_vectors = vectorizer.transform(data_test.data) \n",
    "\n",
    "print(data_train_vectors.shape, data_test_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use KNN to do document classification\n",
    "\n",
    "Here, we use the cross-validation method to select $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16846385009722467\n",
      "{'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "Xtr = data_train_vectors\n",
    "Ytr = data_train.target\n",
    "\n",
    "Xte = data_test_vectors\n",
    "Yte = data_test.target\n",
    "\n",
    "k_range = range(1, 5)\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "clf_knn =  KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "grid = GridSearchCV(clf_knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(Xtr, Ytr)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use Logistic Regression to do document classification\n",
    "Here, we also use the cross-validation method to select the regularization coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ghc/Software/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/ghc/Software/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 8}\n",
      "0.6889272437599575 0.6778761181105242 0.6889272437599575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "#=====training with cross validation======\n",
    "coeff = range(1, 10)\n",
    "param_grid = dict(C=coeff)\n",
    "\n",
    "clf_lr = LogisticRegression(penalty='l2')\n",
    "\n",
    "grid = GridSearchCV(clf_lr, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(Xtr, Ytr)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "#=====testing======\n",
    "clf_lr = LogisticRegression(penalty='l2', C=grid.best_params_['C'])\n",
    "clf_lr.fit(Xtr, Ytr)\n",
    "\n",
    "y_pred = clf_lr.predict(Xte)\n",
    "\n",
    "acc = accuracy_score(Yte, y_pred)\n",
    "macro_f1 = f1_score(Yte, y_pred, average='macro')\n",
    "micro_f1 = f1_score(Yte, y_pred, average='micro')\n",
    "\n",
    "print(acc, macro_f1, micro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Task: Document Classification and Clustering\n",
    "\n",
    "In this task, we are going to use [BBCNews](BBC_News_Train.csv) dataset. There are 1490 articles from 5 topics, including tech, business, sport, entertainment, politics. \n",
    "\n",
    "* Task 1: Please use KNN and logistic regression to do classification, and compare their performance.\n",
    "\n",
    "* Task 2: Please use K-means to partition this dataset into 5 clusters and find the representative words in each cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary modules\n",
    "import pandas as pd                                         # for the dataframe\n",
    "import numpy as np                                          # for linear algebra\n",
    "# for TD-IDF representation\n",
    "from sklearn.model_selection import train_test_split        # for splitting the data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # creates a TF-IDF vector from data\n",
    "# for document classification\n",
    "import matplotlib.pyplot as plt                             # used to show bar plot\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score        # for model evaluation\n",
    "# for clustering\n",
    "from scipy.sparse import vstack                             # for concatenating scipy matrices from vectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "DATASET_FILENAME = r'BBC_News_Train.csv'                    # filename of the dataset input\n",
    "TEST_SIZE = 1.0/5.0                                         # proportion of test data\n",
    "SEED = 42                                                   # seed for sampling\n",
    "KILOBYTES_PER_BYTE = 1.0/1024.0                             # for converting bytes to KB\n",
    "MAX_NEIGHBORS = 5                                           # maximum range for KNN\n",
    "MAX_COEFF = 10                                              # maximum logistic parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load data and represent it with TF-IDF representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 total articles\n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "1192 entries\n",
      "1192 non-null Count\n",
      "dtypes: object\n",
      "memory usage: 9.3 KB\n",
      "\n",
      "1192 non-null Count\n",
      "dtypes: object\n",
      "memory usage: 9.3 KB\n",
      "\n",
      "TD-IDF training data shape: (1192, 22591)\n",
      "TD-IDF testing data shape: (298, 22591)\n"
     ]
    }
   ],
   "source": [
    "# load the BBCNews dataset\n",
    "df = pd.read_csv(DATASET_FILENAME)\n",
    "\n",
    "# split the data\n",
    "(ids_train, ids_test, X_df_train, X_df_test, y_train, y_test) = \\\n",
    "    train_test_split(df[df.columns[0]], df[df.columns[1:-1]], df[df.columns[-1]],\n",
    "                     test_size=TEST_SIZE, random_state=SEED)\n",
    "\n",
    "# reshape the X, y\n",
    "#X_train, X_test, y_train, y_test = \\\n",
    "#    (df.values.reshape((np.product(df.shape),))\n",
    "#     for df in (X_df_train, X_df_test, y_df_train, y_df_test))\n",
    "X_train, X_test = \\\n",
    "    (df.values.reshape((np.product(df.shape),))\n",
    "     for df in (X_df_train, X_df_test))\n",
    "\n",
    "\n",
    "#TF-IDF representation for each document\n",
    "vectorizer = TfidfVectorizer()\n",
    "M_train = vectorizer.fit_transform(X_train)\n",
    "M_test = vectorizer.transform(X_test)\n",
    "\n",
    "# get the shape and summary data\n",
    "(TOTAL_ARTICLES, _) = df.shape\n",
    "(N_ARTICLES, ) = X_train.shape\n",
    "\n",
    "# display the number of articles\n",
    "print(r\"{} total articles\".format(TOTAL_ARTICLES))\n",
    "print()\n",
    "print(type(X_train))\n",
    "print(r\"{} entries\".format(N_ARTICLES))\n",
    "print(\"{} non-null Count\".format(sum(X_train != None)))\n",
    "print(r\"dtypes: {}\".format(X_train.dtype))\n",
    "print(r\"memory usage: {:.1f} KB\".format(X_train.nbytes * KILOBYTES_PER_BYTE))\n",
    "print()\n",
    "print(\"{} non-null Count\".format(sum(y_train != None)))\n",
    "print(r\"dtypes: {}\".format(y_train.dtype))\n",
    "print(r\"memory usage: {:.1f} KB\".format(y_train.nbytes * KILOBYTES_PER_BYTE))\n",
    "print()\n",
    "print(r\"TD-IDF training data shape: {}\".format(M_train.shape))\n",
    "print(r\"TD-IDF testing data shape: {}\".format(M_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Use KNN to do document classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the balance of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "sport            283\n",
      "business         261\n",
      "entertainment    227\n",
      "politics         218\n",
      "tech             203\n",
      "Name: Category, dtype: int64\n",
      "spread = 0.1375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the label and its label counts\n",
    "label_column = df.columns[-1]\n",
    "label_counts = y_train.value_counts()\n",
    "spread = label_counts.std()/label_counts.mean()\n",
    "\n",
    "# print and bar plot of the label\n",
    "print(label_column)\n",
    "print(label_counts)\n",
    "print(r\"spread = {:.4f}\".format(spread))\n",
    "label_counts.plot(kind=r'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have multiple classes, we must use averaging.\n",
    "\n",
    "Additionally, we have a spread of $13.75\\,\\%$,\n",
    "root mean square difference between each value and the mean, normalized by the mean,\n",
    "which is significant.\n",
    "Thus, we will use micro-averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORING = r'f1_micro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9177701206005414\n",
      "{'n_neighbors': 4}\n"
     ]
    }
   ],
   "source": [
    "# create a KNN model\n",
    "clf_knn = KNeighborsClassifier()\n",
    "# perform the cross validation with neigbors from [1..MAX_NEIGHBORS]\n",
    "param_grid = dict(n_neighbors=range(1, (1 + MAX_NEIGHBORS)))\n",
    "knn_grid = GridSearchCV(clf_knn, param_grid, scoring=SCORING)\n",
    "knn_grid.fit(M_train, y_train)\n",
    "# display the results\n",
    "print(knn_grid.best_score_)\n",
    "print(knn_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Use Logistic Regression to do document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9672725994163356\n",
      "{'C': 7}\n"
     ]
    }
   ],
   "source": [
    "# create a logistic regression model\n",
    "clf_lr = LogisticRegression(penalty='l2')\n",
    "# perform the cross validation with neigbors from [1..MAX_COEFF]\n",
    "param_grid = dict(C=range(1, (1 + MAX_COEFF)))\n",
    "lr_grid = GridSearchCV(clf_lr, param_grid, scoring=SCORING)\n",
    "lr_grid.fit(M_train, y_train)\n",
    "# display the results\n",
    "print(lr_grid.best_score_)\n",
    "print(lr_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the $4$NN document classification to the Logistic regression with coefficient $7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>micro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.932886</td>\n",
       "      <td>0.931272</td>\n",
       "      <td>0.932886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.973154</td>\n",
       "      <td>0.973174</td>\n",
       "      <td>0.973154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          acc  macro_f1  micro_f1\n",
       "knn  0.932886  0.931272  0.932886\n",
       "lr   0.973154  0.973174  0.973154"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the best parameters for KNN and logistic regression\n",
    "clf_knn = KNeighborsClassifier(**knn_grid.best_params_)\n",
    "clf_lr = LogisticRegression(penalty='l2', **lr_grid.best_params_)\n",
    "\n",
    "accuracies = []\n",
    "macro_f1s = []\n",
    "micro_f1s = []\n",
    "\n",
    "# for each best classifier\n",
    "for clf in (clf_knn, clf_lr):\n",
    "    # retrain\n",
    "    clf.fit(M_train, y_train)\n",
    "    # predict from M_test\n",
    "    y_pred = clf.predict(M_test)\n",
    "    # calculate the scores\n",
    "    # and add them to the lists\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    macro_f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    micro_f1s.append(f1_score(y_test, y_pred, average='micro'))\n",
    "# next clf\n",
    "\n",
    "# assemble the scores data frame\n",
    "scores = pd.DataFrame({r'acc': accuracies,\n",
    "                       r'macro_f1': macro_f1s, r'micro_f1': micro_f1s},\n",
    "                     index=[r'knn', r'lr'])\n",
    "# display the scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the spread of these scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spreads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.029878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_f1</th>\n",
       "      <td>0.031115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_f1</th>\n",
       "      <td>0.029878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           spreads\n",
       "acc       0.029878\n",
       "macro_f1  0.031115\n",
       "micro_f1  0.029878"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_spread = pd.DataFrame((scores.std()/scores.mean()).T, columns=['spreads'])\n",
    "score_spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the tables above that the scores are very close,\n",
    "with a spread of about $0.02988$ for accuracy,\n",
    "$0.03112$ for the macro-averaged $F_1$ score,\n",
    "$0.02988$ for the micro-averaged $F_1$ score.\n",
    "However, the linear regression with coefficient $7$ wins out\n",
    "having both higher accuracy and higher $F_1$ scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Use K-means to do document clustering and find the 10 most representative words in each cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the training and test data for clustering\n",
    "M = vstack((M_train, M_test), format='csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder**: partition this dataset into 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n",
      "232\n",
      "141\n",
      "539\n",
      "244\n"
     ]
    }
   ],
   "source": [
    "# train the K-means model\n",
    "# we are told to use 5 clusters.\n",
    "cluster = KMeans(n_clusters=5, random_state=SEED).fit(M)\n",
    "\n",
    "# get the unique labels from the value count\n",
    "labels = label_counts.index\n",
    "\n",
    "# for each label by number\n",
    "for label_no, _ in enumerate(labels):\n",
    "    ii_label = (cluster.labels_ == label_no)\n",
    "    # print the multiplicity of matched labels\n",
    "    print(ii_label.sum())\n",
    "# next label_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
